{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, rdFingerprintGenerator\n",
    "from rdkit import DataStructs\n",
    "from wrapMordred import mordredWrapper\n",
    "\n",
    "import chemprop\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = 'skin-sensitization'\n",
    "endpoint = 'eye-irritation'\n",
    "\n",
    "loc = r'D:\\School\\Semester3\\Seminar - Reproducibility\\seminar-toxicity\\data'\n",
    "endpoint_loc = os.path.join(loc, endpoint)\n",
    "model = r'D:\\School\\Semester3\\Seminar - Reproducibility\\seminar-toxicity\\src\\models'\n",
    "model_loc = os.path.join(model, endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train.csv'\n",
    "df_train = pd.read_csv(os.path.join(endpoint_loc, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'val.csv'\n",
    "df_val = pd.read_csv(os.path.join(endpoint_loc, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles = df_train['SMILES'].to_numpy()\n",
    "train_labels = df_train['Activity'].to_numpy()\n",
    "\n",
    "val_smiles = df_val['SMILES'].to_numpy()\n",
    "val_labels = df_val['Activity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('val size smiles :', val_smiles.shape)\n",
    "print('val size labels :', val_labels.shape)\n",
    "print('pos samples in val size :', val_labels[val_labels == 1].shape)\n",
    "print('neg samples in val size :', val_labels[val_labels == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAACS(smiles_array, labels):\n",
    "    fps = []\n",
    "    y = []\n",
    "    for smiles, label in zip(smiles_array, labels):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            pass\n",
    "        else:\n",
    "            fps.append(np.array(MACCSkeys.GenMACCSKeys(mol)))\n",
    "            y.append(label)\n",
    "\n",
    "    assert len(fps) == len(y)\n",
    "    \n",
    "    return np.array(fps), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Morgen(smiles_array, labels):\n",
    "    fpg = rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=2048)\n",
    "    fps = []\n",
    "    y = []\n",
    "    for smiles, label in zip(smiles_array, labels):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            pass\n",
    "        else:\n",
    "            fps.append(np.array(fpg.GetFingerprint(mol)))\n",
    "            y.append(label)\n",
    "\n",
    "    assert len(fps) == len(y)\n",
    "    \n",
    "    return np.array(fps), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mordred = mordredWrapper(np.concatenate((train_smiles, val_smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {}\n",
    "input_dict['MAACS'] = {}\n",
    "input_dict['Morgen'] = {}\n",
    "input_dict['Mordred'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict['MAACS']['fingerprints'], input_dict['MAACS']['labels'] = get_MAACS(val_smiles, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict['Morgen']['fingerprints'], input_dict['Morgen']['labels'] = get_Morgen(val_smiles, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict['Mordred']['fingerprints'], input_dict['Mordred']['labels'] = mordred.get_fingerprints(val_smiles, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in input_dict:\n",
    "    print(f'{key} fingerprint stats')\n",
    "    print('val size fingerprints :', input_dict[key]['fingerprints'].shape)\n",
    "    print('val size labels :', input_dict[key]['labels'].shape)\n",
    "    print('pos samples in val size :', input_dict[key]['labels'][input_dict[key]['labels'] == 1].shape)\n",
    "    print('neg samples in val size :', input_dict[key]['labels'][input_dict[key]['labels'] == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for m in ['rf', 'svm']:\n",
    "    for key in input_dict:\n",
    "        model_key = m + '-' + key\n",
    "        model_name = model_key + '.joblib'\n",
    "        models[model_key] = joblib.load(os.path.join(model_loc, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MPNN_pred(endpoint_loc, model_loc, val_labels, filename='val.csv'):\n",
    "    arguments = [\n",
    "        '--test_path', os.path.join(endpoint_loc, filename), \n",
    "        '--preds_path', '/dev/null',\n",
    "        '--checkpoint_dir', model_loc,\n",
    "        '--smiles_columns', 'SMILES',\n",
    "        '--features_generator', 'rdkit_2d_normalized', \n",
    "        '--no_features_scaling'\n",
    "    ]\n",
    "\n",
    "    args = chemprop.args.PredictArgs().parse_args(arguments)\n",
    "    preds = chemprop.train.make_predictions(args=args)\n",
    "\n",
    "    y_pred = (np.array(preds).flatten()[np.where(np.array(preds).flatten() != 'Invalid SMILES')].astype(np.float32) > 0.5).astype(np.int64)\n",
    "    y_true = val_labels[np.where(np.array(preds).flatten() != 'Invalid SMILES')]\n",
    "\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MPNN, y_true_MPNN = get_MPNN_pred(endpoint_loc, model_loc, val_labels, 'val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "measurement = {}\n",
    "measurement['ACC'] = []\n",
    "measurement['SEN'] = []\n",
    "measurement['SPE'] = []\n",
    "xlabels = []\n",
    "for model_key in models:\n",
    "    key = model_key.strip().split('-')[1]\n",
    "\n",
    "    y_pred = models[model_key].predict(input_dict[key]['fingerprints'])\n",
    "    y_true = input_dict[key]['labels']\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred, y_true).ravel()\n",
    "\n",
    "    ACC = (tp + tn)/(tp + tn + fn + fp)\n",
    "    SEN = tp/(tp + fn)\n",
    "    SPE = tn/(tn + fp)\n",
    "\n",
    "    xlabels.append(model_key)\n",
    "    measurement['ACC'].append(ACC)\n",
    "    measurement['SEN'].append(SEN)\n",
    "    measurement['SPE'].append(SPE)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_pred_MPNN, y_true_MPNN).ravel()\n",
    "\n",
    "ACC = (tp + tn)/(tp + tn + fn + fp)\n",
    "SEN = tp/(tp + fn)\n",
    "SPE = tn/(tn + fp)\n",
    "\n",
    "xlabels.append('MPNN')\n",
    "measurement['ACC'].append(ACC)\n",
    "measurement['SEN'].append(SEN)\n",
    "measurement['SPE'].append(SPE)\n",
    "\n",
    "\n",
    "x = np.arange(len(xlabels))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "colours = ['blue', 'red', 'green']\n",
    "for key, value in measurement.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, value, width, label=key, color=colours[multiplier])\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_title('Whole Validation set')\n",
    "ax.set_xticks(x + width, xlabels, rotation= 45, ha= 'right')\n",
    "ax.set_yticks(np.arange(0,11)/10)\n",
    "ax.legend(loc='upper right', ncols=3)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextAID",
   "language": "python",
   "name": "nextaid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
