{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import chemprop\n",
    "\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'skin-sensitization'\n",
    "# endpoint = 'eye-irritation'\n",
    "\n",
    "loc = r'D:\\School\\Semester3\\Seminar - Reproducibility\\seminar-toxicity\\data'\n",
    "endpoint_loc = os.path.join(loc, endpoint)\n",
    "model = r'D:\\School\\Semester3\\Seminar - Reproducibility\\seminar-toxicity\\src\\models'\n",
    "model_loc = os.path.join(model, endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command line\n",
      "python c:\\Users\\kevin\\nextAID\\lib\\site-packages\\ipykernel_launcher.py --f=c:\\Users\\kevin\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-14548w0y6P08OS4Xv.json\n",
      "Args\n",
      "{'activation': 'ReLU',\n",
      " 'adding_bond_types': True,\n",
      " 'adding_h': False,\n",
      " 'aggregation': 'mean',\n",
      " 'aggregation_norm': 100,\n",
      " 'atom_constraints': [],\n",
      " 'atom_descriptor_scaling': True,\n",
      " 'atom_descriptors': None,\n",
      " 'atom_descriptors_path': None,\n",
      " 'atom_descriptors_size': 0,\n",
      " 'atom_features_size': 0,\n",
      " 'atom_messages': False,\n",
      " 'atom_targets': [],\n",
      " 'batch_size': 50,\n",
      " 'bias': False,\n",
      " 'bias_solvent': False,\n",
      " 'bond_constraints': [],\n",
      " 'bond_descriptor_scaling': True,\n",
      " 'bond_descriptors': None,\n",
      " 'bond_descriptors_path': None,\n",
      " 'bond_descriptors_size': 0,\n",
      " 'bond_features_size': 0,\n",
      " 'bond_targets': [],\n",
      " 'cache_cutoff': 10000,\n",
      " 'checkpoint_dir': None,\n",
      " 'checkpoint_frzn': None,\n",
      " 'checkpoint_path': None,\n",
      " 'checkpoint_paths': None,\n",
      " 'class_balance': False,\n",
      " 'config_path': 'D:\\\\School\\\\Semester3\\\\Seminar - '\n",
      "                'Reproducibility\\\\seminar-toxicity\\\\src\\\\models\\\\skin-sensitization\\\\config.json',\n",
      " 'constraints_path': None,\n",
      " 'crossval_index_dir': None,\n",
      " 'crossval_index_file': None,\n",
      " 'crossval_index_sets': None,\n",
      " 'cuda': False,\n",
      " 'data_path': 'D:\\\\School\\\\Semester3\\\\Seminar - '\n",
      "              'Reproducibility\\\\seminar-toxicity\\\\data\\\\skin-sensitization\\\\train.csv',\n",
      " 'data_weights_path': None,\n",
      " 'dataset_type': 'classification',\n",
      " 'depth': 5,\n",
      " 'depth_solvent': 3,\n",
      " 'device': device(type='cpu'),\n",
      " 'dropout': 0.1,\n",
      " 'empty_cache': False,\n",
      " 'ensemble_size': 5,\n",
      " 'epochs': 30,\n",
      " 'evidential_regularization': 0,\n",
      " 'explicit_h': False,\n",
      " 'extra_metrics': ['accuracy'],\n",
      " 'features_generator': ['rdkit_2d_normalized'],\n",
      " 'features_only': False,\n",
      " 'features_path': None,\n",
      " 'features_scaling': False,\n",
      " 'features_size': None,\n",
      " 'ffn_hidden_size': 1700,\n",
      " 'ffn_num_layers': 1,\n",
      " 'final_lr': 0.0001,\n",
      " 'folds_file': None,\n",
      " 'freeze_first_only': False,\n",
      " 'frzn_ffn_layers': 0,\n",
      " 'gpu': None,\n",
      " 'grad_clip': None,\n",
      " 'hidden_size': 1700,\n",
      " 'hidden_size_solvent': 300,\n",
      " 'ignore_columns': None,\n",
      " 'init_lr': 0.0001,\n",
      " 'is_atom_bond_targets': False,\n",
      " 'keeping_atom_map': False,\n",
      " 'log_frequency': 10,\n",
      " 'loss_function': 'binary_cross_entropy',\n",
      " 'max_data_size': None,\n",
      " 'max_lr': 0.001,\n",
      " 'metric': 'auc',\n",
      " 'metrics': ['auc', 'accuracy'],\n",
      " 'minimize_score': False,\n",
      " 'mpn_shared': False,\n",
      " 'multiclass_num_classes': 3,\n",
      " 'no_adding_bond_types': False,\n",
      " 'no_atom_descriptor_scaling': False,\n",
      " 'no_bond_descriptor_scaling': False,\n",
      " 'no_cache_mol': False,\n",
      " 'no_cuda': False,\n",
      " 'no_features_scaling': True,\n",
      " 'no_shared_atom_bond_ffn': False,\n",
      " 'num_folds': 1,\n",
      " 'num_lrs': 1,\n",
      " 'num_tasks': 1,\n",
      " 'num_workers': 8,\n",
      " 'number_of_molecules': 1,\n",
      " 'overwrite_default_atom_features': False,\n",
      " 'overwrite_default_bond_features': False,\n",
      " 'phase_features_path': None,\n",
      " 'pytorch_seed': 0,\n",
      " 'quiet': False,\n",
      " 'reaction': False,\n",
      " 'reaction_mode': 'reac_diff',\n",
      " 'reaction_solvent': False,\n",
      " 'resume_experiment': False,\n",
      " 'save_dir': 'D:\\\\School\\\\Semester3\\\\Seminar - '\n",
      "             'Reproducibility\\\\seminar-toxicity\\\\src\\\\models\\\\skin-sensitization',\n",
      " 'save_preds': False,\n",
      " 'save_smiles_splits': False,\n",
      " 'seed': 0,\n",
      " 'separate_test_atom_descriptors_path': None,\n",
      " 'separate_test_bond_descriptors_path': None,\n",
      " 'separate_test_constraints_path': None,\n",
      " 'separate_test_features_path': None,\n",
      " 'separate_test_path': 'D:\\\\School\\\\Semester3\\\\Seminar - '\n",
      "                       'Reproducibility\\\\seminar-toxicity\\\\data\\\\skin-sensitization\\\\val.csv',\n",
      " 'separate_test_phase_features_path': None,\n",
      " 'separate_val_atom_descriptors_path': None,\n",
      " 'separate_val_bond_descriptors_path': None,\n",
      " 'separate_val_constraints_path': None,\n",
      " 'separate_val_features_path': None,\n",
      " 'separate_val_path': None,\n",
      " 'separate_val_phase_features_path': None,\n",
      " 'shared_atom_bond_ffn': True,\n",
      " 'show_individual_scores': False,\n",
      " 'smiles_columns': ['SMILES'],\n",
      " 'spectra_activation': 'exp',\n",
      " 'spectra_phase_mask_path': None,\n",
      " 'spectra_target_floor': 1e-08,\n",
      " 'split_key_molecule': 0,\n",
      " 'split_sizes': [0.8, 0.2, 0.0],\n",
      " 'split_type': 'random',\n",
      " 'target_columns': ['Activity'],\n",
      " 'target_weights': None,\n",
      " 'task_names': ['Activity'],\n",
      " 'test': False,\n",
      " 'test_fold_index': None,\n",
      " 'train_data_size': None,\n",
      " 'undirected': False,\n",
      " 'use_input_features': True,\n",
      " 'val_fold_index': None,\n",
      " 'warmup_epochs': 2.0,\n",
      " 'weights_ffn_num_layers': 2}\n",
      "Setting molecule featurization parameters to default.\n",
      "Loading data\n",
      "2956it [00:00, 26143.65it/s]\n",
      "100%|██████████| 2956/2956 [01:54<00:00, 25.89it/s]\n",
      "100%|██████████| 2956/2956 [00:00<00:00, 150348.79it/s]\n",
      "Number of tasks = 1\n",
      "Fold 0\n",
      "Splitting data with seed 0\n",
      "739it [00:00, 98455.96it/s]\n",
      " 42%|████▏     | 310/739 [00:11<00:16, 26.27it/s][12:38:50] Can't kekulize mol.  Unkekulized atoms: 0 1 2 3 4\n",
      " 92%|█████████▏| 680/739 [00:25<00:02, 25.13it/s][12:39:04] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 5 6 7 9 10 11 13 14 15\n",
      "100%|██████████| 739/739 [00:28<00:00, 26.37it/s]\n",
      "100%|██████████| 739/739 [00:00<00:00, 93243.21it/s]\n",
      "Warning: 2 SMILES are invalid.\n",
      "Class sizes\n",
      "Activity 0: 45.30%, 1: 54.70%\n",
      "Total size = 2,956 | train size = 2,364 | val size = 592 | test size = 737\n",
      "Building model 0\n",
      "MoleculeModel(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (encoder): MPN(\n",
      "    (encoder): ModuleList(\n",
      "      (0): MPNEncoder(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act_func): ReLU()\n",
      "        (W_i): Linear(in_features=147, out_features=1700, bias=False)\n",
      "        (W_h): Linear(in_features=1700, out_features=1700, bias=False)\n",
      "        (W_o): Linear(in_features=1833, out_features=1700, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=1900, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 6,261,301\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 7.3031e-01, PNorm = 61.1296, GNorm = 1.4761, lr_0 = 2.0532e-04\n",
      "Loss = 6.8881e-01, PNorm = 61.1477, GNorm = 1.4124, lr_0 = 3.0106e-04\n",
      "Loss = 6.9181e-01, PNorm = 61.1710, GNorm = 0.5945, lr_0 = 3.9681e-04\n",
      "Loss = 7.0037e-01, PNorm = 61.1988, GNorm = 0.8599, lr_0 = 4.9255e-04\n",
      "Validation auc = 0.653169\n",
      "Validation accuracy = 0.589527\n",
      "  3%|▎         | 1/30 [01:09<33:30, 69.31s/it]Epoch 1\n",
      "Loss = 6.8543e-01, PNorm = 61.2393, GNorm = 0.3774, lr_0 = 5.9787e-04\n",
      "Loss = 6.7690e-01, PNorm = 61.2864, GNorm = 0.5010, lr_0 = 6.9362e-04\n",
      "Loss = 6.7120e-01, PNorm = 61.3487, GNorm = 0.6975, lr_0 = 7.8936e-04\n",
      "Loss = 6.8355e-01, PNorm = 61.4493, GNorm = 0.5521, lr_0 = 8.8511e-04\n",
      "Loss = 6.8509e-01, PNorm = 61.5812, GNorm = 0.7311, lr_0 = 9.8085e-04\n",
      "Validation auc = 0.668036\n",
      "Validation accuracy = 0.635135\n",
      "  7%|▋         | 2/30 [02:18<32:24, 69.45s/it]Epoch 2\n",
      "Loss = 6.8561e-01, PNorm = 61.7279, GNorm = 0.4484, lr_0 = 9.8438e-04\n",
      "Loss = 6.4952e-01, PNorm = 61.8543, GNorm = 0.3956, lr_0 = 9.6730e-04\n",
      "Loss = 6.6930e-01, PNorm = 61.9791, GNorm = 0.4711, lr_0 = 9.5052e-04\n",
      "Loss = 6.4729e-01, PNorm = 62.0943, GNorm = 0.3788, lr_0 = 9.3404e-04\n",
      "Loss = 6.4715e-01, PNorm = 62.2058, GNorm = 1.0548, lr_0 = 9.1784e-04\n",
      "Validation auc = 0.687055\n",
      "Validation accuracy = 0.569257\n",
      " 10%|█         | 3/30 [03:28<31:21, 69.69s/it]Epoch 3\n",
      "Loss = 6.5320e-01, PNorm = 62.3255, GNorm = 0.8957, lr_0 = 9.0034e-04\n",
      "Loss = 6.5053e-01, PNorm = 62.4505, GNorm = 0.3765, lr_0 = 8.8473e-04\n",
      "Loss = 6.4313e-01, PNorm = 62.5744, GNorm = 0.4831, lr_0 = 8.6938e-04\n",
      "Loss = 6.2706e-01, PNorm = 62.6936, GNorm = 0.5266, lr_0 = 8.5430e-04\n",
      "Validation auc = 0.711890\n",
      "Validation accuracy = 0.655405\n",
      " 13%|█▎        | 4/30 [04:38<30:12, 69.73s/it]Epoch 4\n",
      "Loss = 6.0477e-01, PNorm = 62.8276, GNorm = 0.3210, lr_0 = 8.3948e-04\n",
      "Loss = 6.5831e-01, PNorm = 62.9569, GNorm = 0.3928, lr_0 = 8.2492e-04\n",
      "Loss = 6.3206e-01, PNorm = 63.0719, GNorm = 0.7151, lr_0 = 8.1061e-04\n",
      "Loss = 6.1983e-01, PNorm = 63.1724, GNorm = 0.4391, lr_0 = 7.9656e-04\n",
      "Loss = 6.4636e-01, PNorm = 63.2738, GNorm = 1.2267, lr_0 = 7.8274e-04\n",
      "Validation auc = 0.720092\n",
      "Validation accuracy = 0.660473\n",
      " 17%|█▋        | 5/30 [05:49<29:11, 70.07s/it]Epoch 5\n",
      "Loss = 6.2410e-01, PNorm = 63.4151, GNorm = 0.5514, lr_0 = 7.6782e-04\n",
      "Loss = 6.2847e-01, PNorm = 63.5403, GNorm = 0.6945, lr_0 = 7.5450e-04\n",
      "Loss = 5.9567e-01, PNorm = 63.6885, GNorm = 0.4961, lr_0 = 7.4141e-04\n",
      "Loss = 6.2930e-01, PNorm = 63.8272, GNorm = 0.8195, lr_0 = 7.2855e-04\n",
      "Loss = 6.3555e-01, PNorm = 63.9540, GNorm = 0.4015, lr_0 = 7.1592e-04\n",
      "Validation auc = 0.748884\n",
      "Validation accuracy = 0.675676\n",
      " 20%|██        | 6/30 [07:00<28:11, 70.46s/it]Epoch 6\n",
      "Loss = 5.8079e-01, PNorm = 64.1131, GNorm = 0.6632, lr_0 = 7.0227e-04\n",
      "Loss = 6.2000e-01, PNorm = 64.2471, GNorm = 0.4494, lr_0 = 6.9009e-04\n",
      "Loss = 5.8701e-01, PNorm = 64.3822, GNorm = 0.9056, lr_0 = 6.7812e-04\n",
      "Loss = 5.8054e-01, PNorm = 64.5243, GNorm = 0.4266, lr_0 = 6.6636e-04\n",
      "Loss = 5.9700e-01, PNorm = 64.6657, GNorm = 0.7960, lr_0 = 6.5480e-04\n",
      "Loss = 6.9585e-01, PNorm = 64.6791, GNorm = 0.9117, lr_0 = 6.5366e-04\n",
      "Validation auc = 0.750743\n",
      "Validation accuracy = 0.685811\n",
      " 23%|██▎       | 7/30 [08:11<27:04, 70.61s/it]Epoch 7\n",
      "Loss = 5.9362e-01, PNorm = 64.8455, GNorm = 0.4348, lr_0 = 6.4232e-04\n",
      "Loss = 5.7335e-01, PNorm = 65.0027, GNorm = 0.7199, lr_0 = 6.3118e-04\n",
      "Loss = 5.5798e-01, PNorm = 65.1745, GNorm = 0.5307, lr_0 = 6.2023e-04\n",
      "Loss = 5.6589e-01, PNorm = 65.3435, GNorm = 0.5468, lr_0 = 6.0947e-04\n",
      "Validation auc = 0.759931\n",
      "Validation accuracy = 0.701014\n",
      " 27%|██▋       | 8/30 [09:20<25:43, 70.18s/it]Epoch 8\n",
      "Loss = 5.7211e-01, PNorm = 65.5297, GNorm = 0.5379, lr_0 = 5.9890e-04\n",
      "Loss = 5.6288e-01, PNorm = 65.7088, GNorm = 0.4559, lr_0 = 5.8851e-04\n",
      "Loss = 5.8266e-01, PNorm = 65.8739, GNorm = 0.8040, lr_0 = 5.7831e-04\n",
      "Loss = 5.6152e-01, PNorm = 66.0310, GNorm = 0.5644, lr_0 = 5.6828e-04\n",
      "Loss = 5.4089e-01, PNorm = 66.1852, GNorm = 0.7176, lr_0 = 5.5842e-04\n",
      "Validation auc = 0.764577\n",
      "Validation accuracy = 0.695946\n",
      " 30%|███       | 9/30 [10:29<24:27, 69.88s/it]Epoch 9\n",
      "Loss = 5.4553e-01, PNorm = 66.3503, GNorm = 0.5369, lr_0 = 5.4777e-04\n",
      "Loss = 5.5496e-01, PNorm = 66.5218, GNorm = 0.7491, lr_0 = 5.3827e-04\n",
      "Loss = 5.6565e-01, PNorm = 66.6951, GNorm = 0.4574, lr_0 = 5.2894e-04\n",
      "Loss = 5.4912e-01, PNorm = 66.8694, GNorm = 0.8610, lr_0 = 5.1976e-04\n",
      "Loss = 5.1098e-01, PNorm = 67.0261, GNorm = 0.4730, lr_0 = 5.1075e-04\n",
      "Validation auc = 0.761767\n",
      "Validation accuracy = 0.682432\n",
      " 33%|███▎      | 10/30 [11:38<23:11, 69.60s/it]Epoch 10\n",
      "Loss = 4.6458e-01, PNorm = 67.2108, GNorm = 0.6188, lr_0 = 5.0101e-04\n",
      "Loss = 5.1126e-01, PNorm = 67.3706, GNorm = 0.8961, lr_0 = 4.9232e-04\n",
      "Loss = 5.2600e-01, PNorm = 67.5125, GNorm = 0.8382, lr_0 = 4.8378e-04\n",
      "Loss = 5.2872e-01, PNorm = 67.6432, GNorm = 0.5333, lr_0 = 4.7539e-04\n",
      "Loss = 5.2621e-01, PNorm = 67.7837, GNorm = 1.5462, lr_0 = 4.6715e-04\n",
      "Validation auc = 0.773502\n",
      "Validation accuracy = 0.709459\n",
      " 37%|███▋      | 11/30 [12:47<21:59, 69.42s/it]Epoch 11\n",
      "Loss = 4.5400e-01, PNorm = 67.9579, GNorm = 0.7770, lr_0 = 4.5904e-04\n",
      "Loss = 4.8479e-01, PNorm = 68.1147, GNorm = 0.7429, lr_0 = 4.5108e-04\n",
      "Loss = 4.8385e-01, PNorm = 68.2811, GNorm = 0.6773, lr_0 = 4.4326e-04\n",
      "Loss = 4.7777e-01, PNorm = 68.4351, GNorm = 0.7841, lr_0 = 4.3557e-04\n",
      "Validation auc = 0.774098\n",
      "Validation accuracy = 0.687500\n",
      " 40%|████      | 12/30 [13:56<20:47, 69.31s/it]Epoch 12\n",
      "Loss = 4.0310e-01, PNorm = 68.5804, GNorm = 0.6620, lr_0 = 4.2727e-04\n",
      "Loss = 4.6420e-01, PNorm = 68.7436, GNorm = 0.5612, lr_0 = 4.1986e-04\n",
      "Loss = 4.5183e-01, PNorm = 68.8981, GNorm = 1.3248, lr_0 = 4.1257e-04\n",
      "Loss = 4.8451e-01, PNorm = 69.0362, GNorm = 1.1205, lr_0 = 4.0542e-04\n",
      "Loss = 4.3370e-01, PNorm = 69.1667, GNorm = 0.7585, lr_0 = 3.9839e-04\n",
      "Validation auc = 0.777516\n",
      "Validation accuracy = 0.711149\n",
      " 43%|████▎     | 13/30 [15:16<20:30, 72.38s/it]Epoch 13\n",
      "Loss = 3.8278e-01, PNorm = 69.3071, GNorm = 1.2079, lr_0 = 3.9079e-04\n",
      "Loss = 4.3948e-01, PNorm = 69.4451, GNorm = 0.6074, lr_0 = 3.8401e-04\n",
      "Loss = 4.0001e-01, PNorm = 69.5787, GNorm = 0.8681, lr_0 = 3.7735e-04\n",
      "Loss = 4.5513e-01, PNorm = 69.7133, GNorm = 0.6584, lr_0 = 3.7081e-04\n",
      "Loss = 4.1629e-01, PNorm = 69.8408, GNorm = 0.9365, lr_0 = 3.6438e-04\n",
      "Validation auc = 0.768730\n",
      "Validation accuracy = 0.695946\n",
      " 47%|████▋     | 14/30 [16:27<19:13, 72.07s/it]Epoch 14\n",
      "Loss = 3.9536e-01, PNorm = 69.9808, GNorm = 1.0590, lr_0 = 3.5743e-04\n",
      "Loss = 3.9086e-01, PNorm = 70.1256, GNorm = 0.8127, lr_0 = 3.5123e-04\n",
      "Loss = 3.9503e-01, PNorm = 70.2526, GNorm = 0.6479, lr_0 = 3.4514e-04\n",
      "Loss = 3.9705e-01, PNorm = 70.3785, GNorm = 1.1563, lr_0 = 3.3915e-04\n",
      "Validation auc = 0.769567\n",
      "Validation accuracy = 0.701014\n",
      " 50%|█████     | 15/30 [17:37<17:48, 71.22s/it]Epoch 15\n",
      "Loss = 3.3124e-01, PNorm = 70.4957, GNorm = 0.8948, lr_0 = 3.3327e-04\n",
      "Loss = 3.5143e-01, PNorm = 70.6145, GNorm = 0.6864, lr_0 = 3.2749e-04\n",
      "Loss = 3.4082e-01, PNorm = 70.7264, GNorm = 0.8709, lr_0 = 3.2181e-04\n",
      "Loss = 3.9418e-01, PNorm = 70.8368, GNorm = 1.1244, lr_0 = 3.1623e-04\n",
      "Loss = 3.7105e-01, PNorm = 70.9482, GNorm = 1.2773, lr_0 = 3.1074e-04\n",
      "Validation auc = 0.764302\n",
      "Validation accuracy = 0.694257\n",
      " 53%|█████▎    | 16/30 [18:46<16:28, 70.61s/it]Epoch 16\n",
      "Loss = 3.1059e-01, PNorm = 71.0425, GNorm = 0.6312, lr_0 = 3.0482e-04\n",
      "Loss = 3.3432e-01, PNorm = 71.1408, GNorm = 0.9013, lr_0 = 2.9953e-04\n",
      "Loss = 3.7786e-01, PNorm = 71.2538, GNorm = 1.3514, lr_0 = 2.9434e-04\n",
      "Loss = 3.2455e-01, PNorm = 71.3522, GNorm = 0.6772, lr_0 = 2.8923e-04\n",
      "Loss = 3.4648e-01, PNorm = 71.4564, GNorm = 0.6280, lr_0 = 2.8422e-04\n",
      "Validation auc = 0.773433\n",
      "Validation accuracy = 0.706081\n",
      " 57%|█████▋    | 17/30 [19:55<15:14, 70.32s/it]Epoch 17\n",
      "Loss = 2.7508e-01, PNorm = 71.5621, GNorm = 0.8220, lr_0 = 2.7880e-04\n",
      "Loss = 3.0930e-01, PNorm = 71.6749, GNorm = 0.8400, lr_0 = 2.7396e-04\n",
      "Loss = 3.3593e-01, PNorm = 71.7685, GNorm = 1.6049, lr_0 = 2.6921e-04\n",
      "Loss = 3.1937e-01, PNorm = 71.8670, GNorm = 1.2807, lr_0 = 2.6454e-04\n",
      "Loss = 2.9152e-01, PNorm = 71.9489, GNorm = 0.6791, lr_0 = 2.5995e-04\n",
      "Validation auc = 0.773880\n",
      "Validation accuracy = 0.697635\n",
      " 60%|██████    | 18/30 [21:05<14:00, 70.02s/it]Epoch 18\n",
      "Loss = 2.7531e-01, PNorm = 72.0244, GNorm = 0.7355, lr_0 = 2.5544e-04\n",
      "Loss = 2.4449e-01, PNorm = 72.1081, GNorm = 0.9272, lr_0 = 2.5101e-04\n",
      "Loss = 2.7524e-01, PNorm = 72.1927, GNorm = 1.0916, lr_0 = 2.4666e-04\n",
      "Loss = 2.9448e-01, PNorm = 72.2795, GNorm = 1.4422, lr_0 = 2.4238e-04\n",
      "Validation auc = 0.773089\n",
      "Validation accuracy = 0.699324\n",
      " 63%|██████▎   | 19/30 [22:14<12:49, 69.96s/it]Epoch 19\n",
      "Loss = 2.9988e-01, PNorm = 72.3687, GNorm = 1.2384, lr_0 = 2.3776e-04\n",
      "Loss = 2.1104e-01, PNorm = 72.4586, GNorm = 0.6548, lr_0 = 2.3364e-04\n",
      "Loss = 2.4204e-01, PNorm = 72.5409, GNorm = 0.8477, lr_0 = 2.2958e-04\n",
      "Loss = 2.6106e-01, PNorm = 72.6238, GNorm = 1.2609, lr_0 = 2.2560e-04\n",
      "Loss = 2.9780e-01, PNorm = 72.7011, GNorm = 1.3254, lr_0 = 2.2169e-04\n",
      "Validation auc = 0.780832\n",
      "Validation accuracy = 0.707770\n",
      " 67%|██████▋   | 20/30 [23:26<11:45, 70.51s/it]Epoch 20\n",
      "Loss = 1.9986e-01, PNorm = 72.7860, GNorm = 0.9411, lr_0 = 2.1746e-04\n",
      "Loss = 2.2750e-01, PNorm = 72.8651, GNorm = 2.1217, lr_0 = 2.1369e-04\n",
      "Loss = 1.9684e-01, PNorm = 72.9404, GNorm = 1.0322, lr_0 = 2.0999e-04\n",
      "Loss = 2.6443e-01, PNorm = 73.0094, GNorm = 1.4721, lr_0 = 2.0634e-04\n",
      "Loss = 2.4247e-01, PNorm = 73.0764, GNorm = 0.7180, lr_0 = 2.0276e-04\n",
      "Validation auc = 0.775165\n",
      "Validation accuracy = 0.699324\n",
      " 70%|███████   | 21/30 [24:39<10:39, 71.04s/it]Epoch 21\n",
      "Loss = 2.1956e-01, PNorm = 73.1423, GNorm = 1.2423, lr_0 = 1.9890e-04\n",
      "Loss = 2.1030e-01, PNorm = 73.2063, GNorm = 0.6918, lr_0 = 1.9545e-04\n",
      "Loss = 1.7442e-01, PNorm = 73.2641, GNorm = 0.7584, lr_0 = 1.9206e-04\n",
      "Loss = 1.9768e-01, PNorm = 73.3202, GNorm = 1.0579, lr_0 = 1.8873e-04\n",
      "Loss = 1.9714e-01, PNorm = 73.3803, GNorm = 2.6460, lr_0 = 1.8545e-04\n",
      "Validation auc = 0.767353\n",
      "Validation accuracy = 0.694257\n",
      " 73%|███████▎  | 22/30 [25:49<09:27, 70.89s/it]Epoch 22\n",
      "Loss = 1.5490e-01, PNorm = 73.4425, GNorm = 1.0156, lr_0 = 1.8224e-04\n",
      "Loss = 1.7039e-01, PNorm = 73.4954, GNorm = 0.7213, lr_0 = 1.7908e-04\n",
      "Loss = 2.4296e-01, PNorm = 73.5427, GNorm = 1.2552, lr_0 = 1.7597e-04\n",
      "Loss = 1.6671e-01, PNorm = 73.5930, GNorm = 1.0546, lr_0 = 1.7292e-04\n",
      "Validation auc = 0.772205\n",
      "Validation accuracy = 0.694257\n",
      " 77%|███████▋  | 23/30 [26:58<08:13, 70.44s/it]Epoch 23\n",
      "Loss = 1.7217e-01, PNorm = 73.6453, GNorm = 0.8301, lr_0 = 1.6962e-04\n",
      "Loss = 1.5431e-01, PNorm = 73.6959, GNorm = 0.6946, lr_0 = 1.6668e-04\n",
      "Loss = 1.8205e-01, PNorm = 73.7458, GNorm = 2.0036, lr_0 = 1.6379e-04\n",
      "Loss = 1.5556e-01, PNorm = 73.7933, GNorm = 1.5741, lr_0 = 1.6095e-04\n",
      "Loss = 1.5531e-01, PNorm = 73.8367, GNorm = 1.3735, lr_0 = 1.5816e-04\n",
      "Validation auc = 0.774798\n",
      "Validation accuracy = 0.704392\n",
      " 80%|████████  | 24/30 [28:08<07:01, 70.21s/it]Epoch 24\n",
      "Loss = 1.5490e-01, PNorm = 73.8940, GNorm = 1.0670, lr_0 = 1.5514e-04\n",
      "Loss = 1.5456e-01, PNorm = 73.9398, GNorm = 0.9264, lr_0 = 1.5245e-04\n",
      "Loss = 1.7267e-01, PNorm = 73.9792, GNorm = 1.0517, lr_0 = 1.4981e-04\n",
      "Loss = 1.4318e-01, PNorm = 74.0179, GNorm = 1.3872, lr_0 = 1.4721e-04\n",
      "Loss = 1.5598e-01, PNorm = 74.0595, GNorm = 0.8281, lr_0 = 1.4466e-04\n",
      "Validation auc = 0.766303\n",
      "Validation accuracy = 0.697635\n",
      " 83%|████████▎ | 25/30 [29:18<05:50, 70.11s/it]Epoch 25\n",
      "Loss = 1.0174e-01, PNorm = 74.0979, GNorm = 0.5763, lr_0 = 1.4215e-04\n",
      "Loss = 1.3535e-01, PNorm = 74.1363, GNorm = 0.6444, lr_0 = 1.3968e-04\n",
      "Loss = 1.3905e-01, PNorm = 74.1698, GNorm = 0.6929, lr_0 = 1.3726e-04\n",
      "Loss = 1.4014e-01, PNorm = 74.1973, GNorm = 0.8309, lr_0 = 1.3488e-04\n",
      "Validation auc = 0.762409\n",
      "Validation accuracy = 0.707770\n",
      " 87%|████████▋ | 26/30 [30:28<04:39, 69.95s/it]Epoch 26\n",
      "Loss = 9.8101e-02, PNorm = 74.2311, GNorm = 1.0018, lr_0 = 1.3231e-04\n",
      "Loss = 1.2029e-01, PNorm = 74.2625, GNorm = 0.8692, lr_0 = 1.3001e-04\n",
      "Loss = 1.1736e-01, PNorm = 74.2927, GNorm = 1.0831, lr_0 = 1.2776e-04\n",
      "Loss = 1.0860e-01, PNorm = 74.3197, GNorm = 1.1202, lr_0 = 1.2554e-04\n",
      "Loss = 1.3819e-01, PNorm = 74.3449, GNorm = 1.2159, lr_0 = 1.2336e-04\n",
      "Validation auc = 0.768271\n",
      "Validation accuracy = 0.695946\n",
      " 90%|█████████ | 27/30 [31:37<03:29, 69.77s/it]Epoch 27\n",
      "Loss = 1.1753e-01, PNorm = 74.3823, GNorm = 0.6884, lr_0 = 1.2101e-04\n",
      "Loss = 1.0394e-01, PNorm = 74.4123, GNorm = 0.7200, lr_0 = 1.1891e-04\n",
      "Loss = 1.1564e-01, PNorm = 74.4421, GNorm = 0.6519, lr_0 = 1.1685e-04\n",
      "Loss = 1.2897e-01, PNorm = 74.4674, GNorm = 0.9212, lr_0 = 1.1482e-04\n",
      "Loss = 1.0856e-01, PNorm = 74.4954, GNorm = 0.6880, lr_0 = 1.1283e-04\n",
      "Validation auc = 0.766779\n",
      "Validation accuracy = 0.694257\n",
      " 93%|█████████▎| 28/30 [32:47<02:19, 69.80s/it]Epoch 28\n",
      "Loss = 1.0770e-01, PNorm = 74.5199, GNorm = 0.6326, lr_0 = 1.1068e-04\n",
      "Loss = 1.0345e-01, PNorm = 74.5450, GNorm = 1.0745, lr_0 = 1.0876e-04\n",
      "Loss = 9.2085e-02, PNorm = 74.5645, GNorm = 0.9943, lr_0 = 1.0687e-04\n",
      "Loss = 9.3207e-02, PNorm = 74.5842, GNorm = 2.4139, lr_0 = 1.0502e-04\n",
      "Loss = 1.0225e-01, PNorm = 74.6081, GNorm = 1.3299, lr_0 = 1.0320e-04\n",
      "Validation auc = 0.764147\n",
      "Validation accuracy = 0.711149\n",
      " 97%|█████████▋| 29/30 [33:56<01:09, 69.75s/it]Epoch 29\n",
      "Loss = 8.9581e-02, PNorm = 74.6328, GNorm = 1.3160, lr_0 = 1.0141e-04\n",
      "Loss = 8.8688e-02, PNorm = 74.6541, GNorm = 1.0008, lr_0 = 1.0000e-04\n",
      "Loss = 1.0883e-01, PNorm = 74.6794, GNorm = 1.1015, lr_0 = 1.0000e-04\n",
      "Loss = 9.6555e-02, PNorm = 74.7024, GNorm = 0.7564, lr_0 = 1.0000e-04\n",
      "Validation auc = 0.769441\n",
      "Validation accuracy = 0.701014\n",
      "100%|██████████| 30/30 [35:07<00:00, 70.26s/it]\n",
      "Model 0 best validation auc = 0.780832 on epoch 19\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Model 0 test auc = 0.732240                    \n",
      "Model 0 test accuracy = 0.666214\n",
      "Building model 1\n",
      "MoleculeModel(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (encoder): MPN(\n",
      "    (encoder): ModuleList(\n",
      "      (0): MPNEncoder(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act_func): ReLU()\n",
      "        (W_i): Linear(in_features=147, out_features=1700, bias=False)\n",
      "        (W_h): Linear(in_features=1700, out_features=1700, bias=False)\n",
      "        (W_o): Linear(in_features=1833, out_features=1700, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=1900, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 6,261,301\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 7.3032e-01, PNorm = 61.1317, GNorm = 1.0530, lr_0 = 2.0532e-04\n",
      "Loss = 6.8845e-01, PNorm = 61.1504, GNorm = 1.3105, lr_0 = 3.0106e-04\n",
      "Loss = 6.6914e-01, PNorm = 61.1784, GNorm = 0.5395, lr_0 = 3.9681e-04\n",
      "Loss = 6.9417e-01, PNorm = 61.2138, GNorm = 0.4052, lr_0 = 4.9255e-04\n",
      "Validation auc = 0.643395\n",
      "Validation accuracy = 0.640203\n",
      "  3%|▎         | 1/30 [01:10<34:11, 70.73s/it]Epoch 1\n",
      "Loss = 6.8232e-01, PNorm = 61.2603, GNorm = 0.3205, lr_0 = 5.9787e-04\n",
      "Loss = 6.9820e-01, PNorm = 61.3194, GNorm = 0.3218, lr_0 = 6.9362e-04\n",
      "Loss = 6.6438e-01, PNorm = 61.3968, GNorm = 0.4352, lr_0 = 7.8936e-04\n",
      "Loss = 6.6064e-01, PNorm = 61.4817, GNorm = 0.4062, lr_0 = 8.8511e-04\n",
      "Loss = 6.7368e-01, PNorm = 61.5823, GNorm = 0.4924, lr_0 = 9.8085e-04\n",
      "Validation auc = 0.654328\n",
      "Validation accuracy = 0.550676\n",
      "  7%|▋         | 2/30 [02:21<33:01, 70.78s/it]Epoch 2\n",
      "Loss = 6.5820e-01, PNorm = 61.7352, GNorm = 0.3610, lr_0 = 9.8438e-04\n",
      "Loss = 6.5337e-01, PNorm = 61.8789, GNorm = 0.3021, lr_0 = 9.6730e-04\n",
      "Loss = 6.7051e-01, PNorm = 61.9989, GNorm = 0.3412, lr_0 = 9.5052e-04\n",
      "Loss = 6.6034e-01, PNorm = 62.1132, GNorm = 0.4389, lr_0 = 9.3404e-04\n",
      "Loss = 6.4400e-01, PNorm = 62.2377, GNorm = 0.3580, lr_0 = 9.1784e-04\n",
      "Validation auc = 0.696587\n",
      "Validation accuracy = 0.653716\n",
      " 10%|█         | 3/30 [03:31<31:42, 70.46s/it]Epoch 3\n",
      "Loss = 6.4588e-01, PNorm = 62.3879, GNorm = 0.3693, lr_0 = 9.0034e-04\n",
      "Loss = 6.3560e-01, PNorm = 62.5456, GNorm = 1.5065, lr_0 = 8.8473e-04\n",
      "Loss = 6.5758e-01, PNorm = 62.7001, GNorm = 0.3004, lr_0 = 8.6938e-04\n",
      "Loss = 6.3401e-01, PNorm = 62.8465, GNorm = 0.4868, lr_0 = 8.5430e-04\n",
      "Validation auc = 0.701508\n",
      "Validation accuracy = 0.648649\n",
      " 13%|█▎        | 4/30 [04:45<31:12, 72.00s/it]Epoch 4\n",
      "Loss = 6.1575e-01, PNorm = 62.9566, GNorm = 0.6315, lr_0 = 8.3948e-04\n",
      "Loss = 6.2609e-01, PNorm = 63.0796, GNorm = 0.4308, lr_0 = 8.2492e-04\n",
      "Loss = 6.2868e-01, PNorm = 63.2081, GNorm = 0.3691, lr_0 = 8.1061e-04\n",
      "Loss = 6.1085e-01, PNorm = 63.3551, GNorm = 0.3760, lr_0 = 7.9656e-04\n",
      "Loss = 6.2961e-01, PNorm = 63.4841, GNorm = 0.4221, lr_0 = 7.8274e-04\n",
      "Validation auc = 0.736794\n",
      "Validation accuracy = 0.668919\n",
      " 17%|█▋        | 5/30 [05:57<29:59, 71.98s/it]Epoch 5\n",
      "Loss = 6.2166e-01, PNorm = 63.6130, GNorm = 0.7249, lr_0 = 7.6782e-04\n",
      "Loss = 6.0769e-01, PNorm = 63.7659, GNorm = 0.4644, lr_0 = 7.5450e-04\n",
      "Loss = 6.0162e-01, PNorm = 63.9044, GNorm = 0.3358, lr_0 = 7.4141e-04\n",
      "Loss = 5.9001e-01, PNorm = 64.0382, GNorm = 0.4505, lr_0 = 7.2855e-04\n",
      "Loss = 6.2501e-01, PNorm = 64.1618, GNorm = 0.4731, lr_0 = 7.1592e-04\n",
      "Validation auc = 0.742277\n",
      "Validation accuracy = 0.668919\n",
      " 20%|██        | 6/30 [07:09<28:41, 71.73s/it]Epoch 6\n",
      "Loss = 5.9517e-01, PNorm = 64.2994, GNorm = 0.4954, lr_0 = 7.0227e-04\n",
      "Loss = 5.9990e-01, PNorm = 64.4395, GNorm = 0.5538, lr_0 = 6.9009e-04\n",
      "Loss = 6.3754e-01, PNorm = 64.5768, GNorm = 0.5200, lr_0 = 6.7812e-04\n",
      "Loss = 5.6696e-01, PNorm = 64.7461, GNorm = 0.8082, lr_0 = 6.6636e-04\n",
      "Loss = 5.8518e-01, PNorm = 64.8995, GNorm = 1.0809, lr_0 = 6.5480e-04\n",
      "Loss = 4.8151e-01, PNorm = 64.9154, GNorm = 0.7376, lr_0 = 6.5366e-04\n",
      "Validation auc = 0.760803\n",
      "Validation accuracy = 0.701014\n",
      " 23%|██▎       | 7/30 [08:19<27:18, 71.22s/it]Epoch 7\n",
      "Loss = 5.6632e-01, PNorm = 65.0848, GNorm = 0.4893, lr_0 = 6.4232e-04\n",
      "Loss = 5.6047e-01, PNorm = 65.2584, GNorm = 0.7502, lr_0 = 6.3118e-04\n",
      "Loss = 5.5909e-01, PNorm = 65.4260, GNorm = 0.9694, lr_0 = 6.2023e-04\n",
      "Loss = 5.7028e-01, PNorm = 65.5789, GNorm = 0.5546, lr_0 = 6.0947e-04\n",
      "Validation auc = 0.756169\n",
      "Validation accuracy = 0.672297\n",
      " 27%|██▋       | 8/30 [09:29<25:57, 70.82s/it]Epoch 8\n",
      "Loss = 4.9758e-01, PNorm = 65.7167, GNorm = 0.3727, lr_0 = 5.9890e-04\n",
      "Loss = 5.8193e-01, PNorm = 65.8590, GNorm = 0.6561, lr_0 = 5.8851e-04\n",
      "Loss = 5.5227e-01, PNorm = 66.0255, GNorm = 0.4567, lr_0 = 5.7831e-04\n",
      "Loss = 5.2430e-01, PNorm = 66.1773, GNorm = 0.7709, lr_0 = 5.6828e-04\n",
      "Loss = 5.7164e-01, PNorm = 66.3159, GNorm = 0.4522, lr_0 = 5.5842e-04\n",
      "Validation auc = 0.761262\n",
      "Validation accuracy = 0.694257\n",
      " 30%|███       | 9/30 [10:38<24:37, 70.37s/it]Epoch 9\n",
      "Loss = 5.3198e-01, PNorm = 66.4852, GNorm = 1.0151, lr_0 = 5.4777e-04\n",
      "Loss = 5.1504e-01, PNorm = 66.6638, GNorm = 0.8423, lr_0 = 5.3827e-04\n",
      "Loss = 5.1625e-01, PNorm = 66.8332, GNorm = 0.7897, lr_0 = 5.2894e-04\n",
      "Loss = 5.3060e-01, PNorm = 67.0132, GNorm = 0.6632, lr_0 = 5.1976e-04\n",
      "Loss = 5.3624e-01, PNorm = 67.1562, GNorm = 0.4506, lr_0 = 5.1075e-04\n",
      "Validation auc = 0.776094\n",
      "Validation accuracy = 0.689189\n",
      " 33%|███▎      | 10/30 [11:48<23:22, 70.12s/it]Epoch 10\n",
      "Loss = 5.1207e-01, PNorm = 67.3168, GNorm = 0.5720, lr_0 = 5.0101e-04\n",
      "Loss = 5.0799e-01, PNorm = 67.4657, GNorm = 0.7415, lr_0 = 4.9232e-04\n",
      "Loss = 4.5632e-01, PNorm = 67.6257, GNorm = 0.5304, lr_0 = 4.8378e-04\n",
      "Loss = 4.9976e-01, PNorm = 67.8013, GNorm = 0.7102, lr_0 = 4.7539e-04\n",
      "Loss = 5.4452e-01, PNorm = 67.9829, GNorm = 1.1892, lr_0 = 4.6715e-04\n",
      "Validation auc = 0.768087\n",
      "Validation accuracy = 0.692568\n",
      " 37%|███▋      | 11/30 [12:57<22:08, 69.91s/it]Epoch 11\n",
      "Loss = 4.7227e-01, PNorm = 68.1684, GNorm = 0.8705, lr_0 = 4.5904e-04\n",
      "Loss = 4.7945e-01, PNorm = 68.3121, GNorm = 0.5957, lr_0 = 4.5108e-04\n",
      "Loss = 4.7772e-01, PNorm = 68.4548, GNorm = 1.0788, lr_0 = 4.4326e-04\n",
      "Loss = 4.6275e-01, PNorm = 68.6060, GNorm = 0.8469, lr_0 = 4.3557e-04\n",
      "Validation auc = 0.774259\n",
      "Validation accuracy = 0.697635\n",
      " 40%|████      | 12/30 [14:07<20:57, 69.86s/it]Epoch 12\n",
      "Loss = 4.7868e-01, PNorm = 68.7606, GNorm = 0.7542, lr_0 = 4.2727e-04\n",
      "Loss = 4.3200e-01, PNorm = 68.9196, GNorm = 0.7007, lr_0 = 4.1986e-04\n",
      "Loss = 4.3582e-01, PNorm = 69.0771, GNorm = 1.0325, lr_0 = 4.1257e-04\n",
      "Loss = 4.0317e-01, PNorm = 69.2352, GNorm = 0.8318, lr_0 = 4.0542e-04\n",
      "Loss = 4.8307e-01, PNorm = 69.3547, GNorm = 0.9374, lr_0 = 3.9839e-04\n",
      "Validation auc = 0.785489\n",
      "Validation accuracy = 0.719595\n",
      " 43%|████▎     | 13/30 [15:18<19:51, 70.09s/it]Epoch 13\n",
      "Loss = 4.3534e-01, PNorm = 69.5078, GNorm = 0.6452, lr_0 = 3.9079e-04\n",
      "Loss = 3.9874e-01, PNorm = 69.6387, GNorm = 1.1915, lr_0 = 3.8401e-04\n",
      "Loss = 4.1153e-01, PNorm = 69.7787, GNorm = 1.0147, lr_0 = 3.7735e-04\n",
      "Loss = 4.2823e-01, PNorm = 69.9190, GNorm = 0.7809, lr_0 = 3.7081e-04\n",
      "Loss = 4.0765e-01, PNorm = 70.0624, GNorm = 0.7779, lr_0 = 3.6438e-04\n",
      "Validation auc = 0.781141\n",
      "Validation accuracy = 0.695946\n",
      " 47%|████▋     | 14/30 [16:38<19:31, 73.22s/it]Epoch 14\n",
      "Loss = 3.6801e-01, PNorm = 70.2319, GNorm = 0.7806, lr_0 = 3.5743e-04\n",
      "Loss = 4.0436e-01, PNorm = 70.3733, GNorm = 1.2654, lr_0 = 3.5123e-04\n",
      "Loss = 3.8938e-01, PNorm = 70.5143, GNorm = 0.6813, lr_0 = 3.4514e-04\n",
      "Loss = 3.8010e-01, PNorm = 70.6389, GNorm = 0.9240, lr_0 = 3.3915e-04\n",
      "Validation auc = 0.783929\n",
      "Validation accuracy = 0.709459\n",
      " 50%|█████     | 15/30 [18:02<19:05, 76.34s/it]Epoch 15\n",
      "Loss = 3.8246e-01, PNorm = 70.7628, GNorm = 1.4499, lr_0 = 3.3327e-04\n",
      "Loss = 3.6616e-01, PNorm = 70.9011, GNorm = 1.4044, lr_0 = 3.2749e-04\n",
      "Loss = 3.5265e-01, PNorm = 71.0212, GNorm = 1.4722, lr_0 = 3.2181e-04\n",
      "Loss = 3.7875e-01, PNorm = 71.1410, GNorm = 0.9768, lr_0 = 3.1623e-04\n",
      "Loss = 3.4001e-01, PNorm = 71.2524, GNorm = 1.3583, lr_0 = 3.1074e-04\n",
      "Validation auc = 0.786992\n",
      "Validation accuracy = 0.722973\n",
      " 53%|█████▎    | 16/30 [19:19<17:51, 76.55s/it]Epoch 16\n",
      "Loss = 2.8237e-01, PNorm = 71.3697, GNorm = 0.7012, lr_0 = 3.0482e-04\n",
      "Loss = 3.1657e-01, PNorm = 71.4752, GNorm = 1.5492, lr_0 = 2.9953e-04\n",
      "Loss = 3.2108e-01, PNorm = 71.5806, GNorm = 0.7197, lr_0 = 2.9434e-04\n",
      "Loss = 3.1581e-01, PNorm = 71.6929, GNorm = 0.6895, lr_0 = 2.8923e-04\n",
      "Loss = 3.4696e-01, PNorm = 71.8043, GNorm = 0.9286, lr_0 = 2.8422e-04\n",
      "Validation auc = 0.776106\n",
      "Validation accuracy = 0.711149\n",
      " 57%|█████▋    | 17/30 [20:37<16:43, 77.16s/it]Epoch 17\n",
      "Loss = 2.6344e-01, PNorm = 71.9160, GNorm = 1.6415, lr_0 = 2.7880e-04\n",
      "Loss = 3.0795e-01, PNorm = 72.0165, GNorm = 1.0084, lr_0 = 2.7396e-04\n",
      "Loss = 2.9288e-01, PNorm = 72.1224, GNorm = 1.8956, lr_0 = 2.6921e-04\n",
      "Loss = 3.0974e-01, PNorm = 72.2291, GNorm = 1.1286, lr_0 = 2.6454e-04\n",
      "Loss = 3.4010e-01, PNorm = 72.3275, GNorm = 1.0216, lr_0 = 2.5995e-04\n",
      "Validation auc = 0.768374\n",
      "Validation accuracy = 0.697635\n",
      " 60%|██████    | 18/30 [21:55<15:29, 77.49s/it]Epoch 18\n",
      "Loss = 2.7736e-01, PNorm = 72.4235, GNorm = 0.8737, lr_0 = 2.5544e-04\n",
      "Loss = 2.6785e-01, PNorm = 72.5200, GNorm = 1.3407, lr_0 = 2.5101e-04\n",
      "Loss = 2.7152e-01, PNorm = 72.6017, GNorm = 0.9404, lr_0 = 2.4666e-04\n",
      "Loss = 2.4980e-01, PNorm = 72.6946, GNorm = 0.8026, lr_0 = 2.4238e-04\n",
      "Validation auc = 0.766596\n",
      "Validation accuracy = 0.699324\n",
      " 63%|██████▎   | 19/30 [23:12<14:08, 77.18s/it]Epoch 19\n",
      "Loss = 2.5930e-01, PNorm = 72.7763, GNorm = 0.9254, lr_0 = 2.3776e-04\n",
      "Loss = 2.4206e-01, PNorm = 72.8549, GNorm = 1.7562, lr_0 = 2.3364e-04\n",
      "Loss = 2.3727e-01, PNorm = 72.9292, GNorm = 0.9407, lr_0 = 2.2958e-04\n",
      "Loss = 2.3033e-01, PNorm = 72.9975, GNorm = 1.5880, lr_0 = 2.2560e-04\n",
      "Loss = 2.3484e-01, PNorm = 73.0703, GNorm = 1.5448, lr_0 = 2.2169e-04\n",
      "Validation auc = 0.773467\n",
      "Validation accuracy = 0.702703\n",
      " 67%|██████▋   | 20/30 [24:30<12:55, 77.57s/it]Epoch 20\n",
      "Loss = 2.0810e-01, PNorm = 73.1446, GNorm = 0.7009, lr_0 = 2.1746e-04\n",
      "Loss = 2.1870e-01, PNorm = 73.2132, GNorm = 1.3248, lr_0 = 2.1369e-04\n",
      "Loss = 2.3532e-01, PNorm = 73.2883, GNorm = 1.4709, lr_0 = 2.0999e-04\n",
      "Loss = 1.8120e-01, PNorm = 73.3561, GNorm = 0.7808, lr_0 = 2.0634e-04\n",
      "Loss = 2.1514e-01, PNorm = 73.4213, GNorm = 0.9603, lr_0 = 2.0276e-04\n",
      "Validation auc = 0.773318\n",
      "Validation accuracy = 0.714527\n",
      " 70%|███████   | 21/30 [25:43<11:25, 76.18s/it]Epoch 21\n",
      "Loss = 1.9175e-01, PNorm = 73.4914, GNorm = 0.8586, lr_0 = 1.9890e-04\n",
      "Loss = 1.6815e-01, PNorm = 73.5490, GNorm = 1.9569, lr_0 = 1.9545e-04\n",
      "Loss = 2.0348e-01, PNorm = 73.6052, GNorm = 1.9059, lr_0 = 1.9206e-04\n",
      "Loss = 2.3969e-01, PNorm = 73.6655, GNorm = 1.3688, lr_0 = 1.8873e-04\n",
      "Loss = 2.1090e-01, PNorm = 73.7351, GNorm = 2.8747, lr_0 = 1.8545e-04\n",
      "Validation auc = 0.773031\n",
      "Validation accuracy = 0.704392\n",
      " 73%|███████▎  | 22/30 [27:09<10:31, 79.00s/it]Epoch 22\n",
      "Loss = 1.5000e-01, PNorm = 73.7968, GNorm = 0.8188, lr_0 = 1.8224e-04\n",
      "Loss = 1.6022e-01, PNorm = 73.8507, GNorm = 1.4811, lr_0 = 1.7908e-04\n",
      "Loss = 1.7848e-01, PNorm = 73.9066, GNorm = 1.1744, lr_0 = 1.7597e-04\n",
      "Loss = 2.0070e-01, PNorm = 73.9608, GNorm = 0.8798, lr_0 = 1.7292e-04\n",
      "Validation auc = 0.769739\n",
      "Validation accuracy = 0.704392\n",
      " 77%|███████▋  | 23/30 [28:38<09:34, 82.03s/it]Epoch 23\n",
      "Loss = 1.5954e-01, PNorm = 74.0209, GNorm = 1.0908, lr_0 = 1.6962e-04\n",
      "Loss = 1.5770e-01, PNorm = 74.0682, GNorm = 1.0078, lr_0 = 1.6668e-04\n",
      "Loss = 1.5898e-01, PNorm = 74.1127, GNorm = 0.9691, lr_0 = 1.6379e-04\n",
      "Loss = 1.5091e-01, PNorm = 74.1535, GNorm = 0.8579, lr_0 = 1.6095e-04\n",
      "Loss = 1.7024e-01, PNorm = 74.1962, GNorm = 1.0439, lr_0 = 1.5816e-04\n",
      "Validation auc = 0.771070\n",
      "Validation accuracy = 0.712838\n",
      " 80%|████████  | 24/30 [29:56<08:04, 80.77s/it]Epoch 24\n",
      "Loss = 1.5523e-01, PNorm = 74.2491, GNorm = 0.8025, lr_0 = 1.5514e-04\n",
      "Loss = 1.5608e-01, PNorm = 74.2862, GNorm = 0.8057, lr_0 = 1.5245e-04\n",
      "Loss = 1.3334e-01, PNorm = 74.3236, GNorm = 1.0394, lr_0 = 1.4981e-04\n",
      "Loss = 1.2770e-01, PNorm = 74.3637, GNorm = 1.1072, lr_0 = 1.4721e-04\n",
      "Loss = 1.2071e-01, PNorm = 74.3985, GNorm = 0.8526, lr_0 = 1.4466e-04\n",
      "Validation auc = 0.764061\n",
      "Validation accuracy = 0.690878\n",
      " 83%|████████▎ | 25/30 [31:20<06:48, 81.70s/it]Epoch 25\n",
      "Loss = 1.0193e-01, PNorm = 74.4300, GNorm = 1.0288, lr_0 = 1.4215e-04\n",
      "Loss = 1.1032e-01, PNorm = 74.4618, GNorm = 1.2331, lr_0 = 1.3968e-04\n",
      "Loss = 1.4875e-01, PNorm = 74.4985, GNorm = 1.3434, lr_0 = 1.3726e-04\n",
      "Loss = 1.2983e-01, PNorm = 74.5329, GNorm = 1.0829, lr_0 = 1.3488e-04\n",
      "Validation auc = 0.776077\n",
      "Validation accuracy = 0.701014\n",
      " 87%|████████▋ | 26/30 [33:04<05:54, 88.59s/it]Epoch 26\n",
      "Loss = 1.5019e-01, PNorm = 74.5635, GNorm = 0.9686, lr_0 = 1.3231e-04\n",
      "Loss = 1.1114e-01, PNorm = 74.5952, GNorm = 1.0008, lr_0 = 1.3001e-04\n",
      "Loss = 1.0794e-01, PNorm = 74.6245, GNorm = 1.0359, lr_0 = 1.2776e-04\n",
      "Loss = 1.1263e-01, PNorm = 74.6602, GNorm = 0.9633, lr_0 = 1.2554e-04\n",
      "Loss = 1.5158e-01, PNorm = 74.6950, GNorm = 0.9560, lr_0 = 1.2336e-04\n",
      "Validation auc = 0.768896\n",
      "Validation accuracy = 0.699324\n",
      " 90%|█████████ | 27/30 [34:50<04:40, 93.61s/it]Epoch 27\n",
      "Loss = 1.0995e-01, PNorm = 74.7306, GNorm = 0.5919, lr_0 = 1.2101e-04\n",
      "Loss = 9.4549e-02, PNorm = 74.7571, GNorm = 0.7737, lr_0 = 1.1891e-04\n",
      "Loss = 1.1613e-01, PNorm = 74.7802, GNorm = 1.2158, lr_0 = 1.1685e-04\n",
      "Loss = 1.1630e-01, PNorm = 74.8053, GNorm = 0.9025, lr_0 = 1.1482e-04\n",
      "Loss = 1.1120e-01, PNorm = 74.8289, GNorm = 1.3627, lr_0 = 1.1283e-04\n",
      "Validation auc = 0.770186\n",
      "Validation accuracy = 0.697635\n",
      " 93%|█████████▎| 28/30 [36:41<03:17, 98.87s/it]Epoch 28\n",
      "Loss = 1.1381e-01, PNorm = 74.8551, GNorm = 1.0336, lr_0 = 1.1068e-04\n",
      "Loss = 9.8644e-02, PNorm = 74.8751, GNorm = 0.5957, lr_0 = 1.0876e-04\n",
      "Loss = 9.7523e-02, PNorm = 74.9005, GNorm = 0.8400, lr_0 = 1.0687e-04\n",
      "Loss = 1.0304e-01, PNorm = 74.9226, GNorm = 1.0920, lr_0 = 1.0502e-04\n",
      "Loss = 1.2259e-01, PNorm = 74.9452, GNorm = 1.6359, lr_0 = 1.0320e-04\n",
      "Validation auc = 0.771236\n",
      "Validation accuracy = 0.702703\n",
      " 97%|█████████▋| 29/30 [38:09<01:35, 95.81s/it]Epoch 29\n",
      "Loss = 6.9656e-02, PNorm = 74.9685, GNorm = 0.8314, lr_0 = 1.0141e-04\n",
      "Loss = 8.9165e-02, PNorm = 74.9897, GNorm = 0.9211, lr_0 = 1.0000e-04\n",
      "Loss = 1.2095e-01, PNorm = 75.0064, GNorm = 1.2327, lr_0 = 1.0000e-04\n",
      "Loss = 1.0132e-01, PNorm = 75.0268, GNorm = 0.9418, lr_0 = 1.0000e-04\n",
      "Validation auc = 0.770634\n",
      "Validation accuracy = 0.701014\n",
      "100%|██████████| 30/30 [39:36<00:00, 79.23s/it]\n",
      "Model 1 best validation auc = 0.786992 on epoch 15\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Model 1 test auc = 0.731765                    \n",
      "Model 1 test accuracy = 0.674355\n",
      "Building model 2\n",
      "MoleculeModel(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (encoder): MPN(\n",
      "    (encoder): ModuleList(\n",
      "      (0): MPNEncoder(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act_func): ReLU()\n",
      "        (W_i): Linear(in_features=147, out_features=1700, bias=False)\n",
      "        (W_h): Linear(in_features=1700, out_features=1700, bias=False)\n",
      "        (W_o): Linear(in_features=1833, out_features=1700, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=1900, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 6,261,301\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 7.2491e-01, PNorm = 61.1452, GNorm = 0.9916, lr_0 = 2.0532e-04\n",
      "Loss = 6.9758e-01, PNorm = 61.1660, GNorm = 1.0450, lr_0 = 3.0106e-04\n",
      "Loss = 6.8466e-01, PNorm = 61.1944, GNorm = 0.5562, lr_0 = 3.9681e-04\n",
      "Loss = 6.7618e-01, PNorm = 61.2237, GNorm = 0.7115, lr_0 = 4.9255e-04\n",
      "Validation auc = 0.671924\n",
      "Validation accuracy = 0.601351\n",
      "  3%|▎         | 1/30 [01:36<46:28, 96.16s/it]Epoch 1\n",
      "Loss = 6.7006e-01, PNorm = 61.2588, GNorm = 0.3299, lr_0 = 5.9787e-04\n",
      "Loss = 6.7292e-01, PNorm = 61.3078, GNorm = 0.3323, lr_0 = 6.9362e-04\n",
      "Loss = 6.7518e-01, PNorm = 61.3735, GNorm = 0.3096, lr_0 = 7.8936e-04\n",
      "Loss = 6.8711e-01, PNorm = 61.4756, GNorm = 0.5921, lr_0 = 8.8511e-04\n",
      "Loss = 6.4931e-01, PNorm = 61.6025, GNorm = 0.6749, lr_0 = 9.8085e-04\n",
      "Validation auc = 0.669940\n",
      "Validation accuracy = 0.597973\n",
      "  7%|▋         | 2/30 [03:00<41:45, 89.49s/it]Epoch 2\n",
      "Loss = 6.7455e-01, PNorm = 61.7375, GNorm = 0.3309, lr_0 = 9.8438e-04\n",
      "Loss = 6.8052e-01, PNorm = 61.8805, GNorm = 0.6416, lr_0 = 9.6730e-04\n",
      "Loss = 6.6340e-01, PNorm = 62.0033, GNorm = 0.8055, lr_0 = 9.5052e-04\n",
      "Loss = 6.4919e-01, PNorm = 62.1206, GNorm = 0.3090, lr_0 = 9.3404e-04\n",
      "Loss = 6.8137e-01, PNorm = 62.2326, GNorm = 0.8077, lr_0 = 9.1784e-04\n",
      "Validation auc = 0.655945\n",
      "Validation accuracy = 0.554054\n",
      " 10%|█         | 3/30 [04:25<39:15, 87.24s/it]Epoch 3\n",
      "Loss = 6.7566e-01, PNorm = 62.3596, GNorm = 0.5116, lr_0 = 9.0034e-04\n",
      "Loss = 6.4226e-01, PNorm = 62.4897, GNorm = 0.3190, lr_0 = 8.8473e-04\n",
      "Loss = 6.7462e-01, PNorm = 62.5802, GNorm = 0.4870, lr_0 = 8.6938e-04\n",
      "Loss = 6.5737e-01, PNorm = 62.6746, GNorm = 0.8534, lr_0 = 8.5430e-04\n",
      "Validation auc = 0.730691\n",
      "Validation accuracy = 0.641892\n",
      " 13%|█▎        | 4/30 [05:51<37:36, 86.79s/it]Epoch 4\n",
      "Loss = 6.1294e-01, PNorm = 62.7709, GNorm = 0.2953, lr_0 = 8.3948e-04\n",
      "Loss = 6.2669e-01, PNorm = 62.8900, GNorm = 0.5087, lr_0 = 8.2492e-04\n",
      "Loss = 6.6764e-01, PNorm = 63.0052, GNorm = 0.7816, lr_0 = 8.1061e-04\n",
      "Loss = 6.4797e-01, PNorm = 63.1059, GNorm = 0.3753, lr_0 = 7.9656e-04\n",
      "Loss = 6.2843e-01, PNorm = 63.2230, GNorm = 0.7167, lr_0 = 7.8274e-04\n",
      "Validation auc = 0.748793\n",
      "Validation accuracy = 0.652027\n",
      " 17%|█▋        | 5/30 [07:50<40:55, 98.21s/it]Epoch 5\n",
      "Loss = 6.0269e-01, PNorm = 63.3448, GNorm = 0.3150, lr_0 = 7.6782e-04\n",
      "Loss = 6.3444e-01, PNorm = 63.4659, GNorm = 0.7013, lr_0 = 7.5450e-04\n",
      "Loss = 6.0450e-01, PNorm = 63.6018, GNorm = 0.9844, lr_0 = 7.4141e-04\n",
      "Loss = 6.1254e-01, PNorm = 63.7373, GNorm = 0.4301, lr_0 = 7.2855e-04\n",
      "Loss = 6.3845e-01, PNorm = 63.8421, GNorm = 0.7880, lr_0 = 7.1592e-04\n",
      "Validation auc = 0.742346\n",
      "Validation accuracy = 0.684122\n",
      " 20%|██        | 6/30 [09:17<37:44, 94.37s/it]Epoch 6\n",
      "Loss = 5.9476e-01, PNorm = 63.9807, GNorm = 0.5920, lr_0 = 7.0227e-04\n",
      "Loss = 6.0717e-01, PNorm = 64.0932, GNorm = 0.4045, lr_0 = 6.9009e-04\n",
      "Loss = 5.8465e-01, PNorm = 64.2339, GNorm = 0.5052, lr_0 = 6.7812e-04\n",
      "Loss = 6.2638e-01, PNorm = 64.3634, GNorm = 0.5079, lr_0 = 6.6636e-04\n",
      "Loss = 6.0329e-01, PNorm = 64.4984, GNorm = 0.3937, lr_0 = 6.5480e-04\n",
      "Loss = 5.8512e-01, PNorm = 64.5121, GNorm = 1.3672, lr_0 = 6.5366e-04\n",
      "Validation auc = 0.756283\n",
      "Validation accuracy = 0.665541\n",
      " 23%|██▎       | 7/30 [10:40<34:49, 90.83s/it]Epoch 7\n",
      "Loss = 5.9262e-01, PNorm = 64.6702, GNorm = 0.8430, lr_0 = 6.4232e-04\n",
      "Loss = 5.6219e-01, PNorm = 64.8436, GNorm = 0.3963, lr_0 = 6.3118e-04\n",
      "Loss = 6.1386e-01, PNorm = 64.9830, GNorm = 0.5947, lr_0 = 6.2023e-04\n",
      "Loss = 6.0347e-01, PNorm = 65.1270, GNorm = 0.5352, lr_0 = 6.0947e-04\n",
      "Validation auc = 0.761996\n",
      "Validation accuracy = 0.689189\n",
      " 27%|██▋       | 8/30 [11:57<31:42, 86.46s/it]Epoch 8\n",
      "Loss = 6.1719e-01, PNorm = 65.2539, GNorm = 0.7122, lr_0 = 5.9890e-04\n",
      "Loss = 5.8471e-01, PNorm = 65.3857, GNorm = 0.9001, lr_0 = 5.8851e-04\n",
      "Loss = 5.4946e-01, PNorm = 65.5217, GNorm = 0.4068, lr_0 = 5.7831e-04\n",
      "Loss = 5.9693e-01, PNorm = 65.6536, GNorm = 0.4529, lr_0 = 5.6828e-04\n",
      "Loss = 5.5102e-01, PNorm = 65.7671, GNorm = 1.1702, lr_0 = 5.5842e-04\n",
      "Validation auc = 0.778411\n",
      "Validation accuracy = 0.677365\n",
      " 30%|███       | 9/30 [13:17<29:33, 84.47s/it]Epoch 9\n",
      "Loss = 5.3245e-01, PNorm = 65.9283, GNorm = 0.5766, lr_0 = 5.4777e-04\n",
      "Loss = 5.7143e-01, PNorm = 66.0676, GNorm = 0.5286, lr_0 = 5.3827e-04\n",
      "Loss = 4.9329e-01, PNorm = 66.2199, GNorm = 0.9923, lr_0 = 5.2894e-04\n",
      "Loss = 5.5169e-01, PNorm = 66.3681, GNorm = 0.4744, lr_0 = 5.1976e-04\n",
      "Loss = 5.7849e-01, PNorm = 66.5372, GNorm = 0.5354, lr_0 = 5.1075e-04\n",
      "Validation auc = 0.772091\n",
      "Validation accuracy = 0.724662\n",
      " 33%|███▎      | 10/30 [14:35<27:26, 82.34s/it]Epoch 10\n",
      "Loss = 5.2029e-01, PNorm = 66.6883, GNorm = 0.7652, lr_0 = 5.0101e-04\n",
      "Loss = 5.0297e-01, PNorm = 66.8148, GNorm = 0.4823, lr_0 = 4.9232e-04\n",
      "Loss = 5.3025e-01, PNorm = 66.9275, GNorm = 0.8348, lr_0 = 4.8378e-04\n",
      "Loss = 5.6339e-01, PNorm = 67.0491, GNorm = 0.6443, lr_0 = 4.7539e-04\n",
      "Loss = 5.1872e-01, PNorm = 67.1947, GNorm = 1.2671, lr_0 = 4.6715e-04\n",
      "Validation auc = 0.771345\n",
      "Validation accuracy = 0.701014\n",
      " 37%|███▋      | 11/30 [15:50<25:25, 80.27s/it]Epoch 11\n",
      "Loss = 5.0592e-01, PNorm = 67.3363, GNorm = 0.9719, lr_0 = 4.5904e-04\n",
      "Loss = 4.7420e-01, PNorm = 67.4710, GNorm = 0.7962, lr_0 = 4.5108e-04\n",
      "Loss = 5.0937e-01, PNorm = 67.6000, GNorm = 0.5710, lr_0 = 4.4326e-04\n",
      "Loss = 4.7396e-01, PNorm = 67.7373, GNorm = 0.6630, lr_0 = 4.3557e-04\n",
      "Validation auc = 0.770519\n",
      "Validation accuracy = 0.697635\n",
      " 40%|████      | 12/30 [17:07<23:42, 79.02s/it]Epoch 12\n",
      "Loss = 5.0445e-01, PNorm = 67.8877, GNorm = 0.8946, lr_0 = 4.2727e-04\n",
      "Loss = 4.6335e-01, PNorm = 68.0368, GNorm = 0.7666, lr_0 = 4.1986e-04\n",
      "Loss = 4.5300e-01, PNorm = 68.1908, GNorm = 0.6019, lr_0 = 4.1257e-04\n",
      "Loss = 4.8557e-01, PNorm = 68.3429, GNorm = 0.6188, lr_0 = 4.0542e-04\n",
      "Loss = 4.5785e-01, PNorm = 68.4871, GNorm = 0.9747, lr_0 = 3.9839e-04\n",
      "Validation auc = 0.776656\n",
      "Validation accuracy = 0.697635\n",
      " 43%|████▎     | 13/30 [18:23<22:12, 78.37s/it]Epoch 13\n",
      "Loss = 4.1158e-01, PNorm = 68.6284, GNorm = 0.5008, lr_0 = 3.9079e-04\n",
      "Loss = 4.1685e-01, PNorm = 68.7616, GNorm = 0.6468, lr_0 = 3.8401e-04\n",
      "Loss = 4.0768e-01, PNorm = 68.8959, GNorm = 0.8354, lr_0 = 3.7735e-04\n",
      "Loss = 4.7251e-01, PNorm = 69.0390, GNorm = 0.6593, lr_0 = 3.7081e-04\n",
      "Loss = 4.8254e-01, PNorm = 69.1647, GNorm = 0.7224, lr_0 = 3.6438e-04\n",
      "Validation auc = 0.777941\n",
      "Validation accuracy = 0.712838\n",
      " 47%|████▋     | 14/30 [19:41<20:51, 78.20s/it]Epoch 14\n",
      "Loss = 4.0869e-01, PNorm = 69.2926, GNorm = 0.7107, lr_0 = 3.5743e-04\n",
      "Loss = 4.1516e-01, PNorm = 69.4088, GNorm = 0.8383, lr_0 = 3.5123e-04\n",
      "Loss = 3.9166e-01, PNorm = 69.5355, GNorm = 0.7351, lr_0 = 3.4514e-04\n",
      "Loss = 4.2961e-01, PNorm = 69.6596, GNorm = 0.6524, lr_0 = 3.3915e-04\n",
      "Validation auc = 0.784170\n",
      "Validation accuracy = 0.706081\n",
      " 50%|█████     | 15/30 [20:59<19:29, 77.97s/it]Epoch 15\n",
      "Loss = 3.4885e-01, PNorm = 69.7669, GNorm = 0.5858, lr_0 = 3.3327e-04\n",
      "Loss = 4.1392e-01, PNorm = 69.8809, GNorm = 0.9209, lr_0 = 3.2749e-04\n",
      "Loss = 3.8364e-01, PNorm = 69.9867, GNorm = 0.6296, lr_0 = 3.2181e-04\n",
      "Loss = 3.7502e-01, PNorm = 70.0874, GNorm = 1.8640, lr_0 = 3.1623e-04\n",
      "Loss = 4.0610e-01, PNorm = 70.1943, GNorm = 0.7412, lr_0 = 3.1074e-04\n",
      "Validation auc = 0.783046\n",
      "Validation accuracy = 0.711149\n",
      " 53%|█████▎    | 16/30 [22:16<18:09, 77.86s/it]Epoch 16\n",
      "Loss = 3.3024e-01, PNorm = 70.3114, GNorm = 0.9050, lr_0 = 3.0482e-04\n",
      "Loss = 3.6342e-01, PNorm = 70.4091, GNorm = 1.3013, lr_0 = 2.9953e-04\n",
      "Loss = 3.4783e-01, PNorm = 70.5140, GNorm = 0.8460, lr_0 = 2.9434e-04\n",
      "Loss = 3.4631e-01, PNorm = 70.6122, GNorm = 0.9887, lr_0 = 2.8923e-04\n",
      "Loss = 3.3433e-01, PNorm = 70.7135, GNorm = 1.0701, lr_0 = 2.8422e-04\n",
      "Validation auc = 0.788437\n",
      "Validation accuracy = 0.731419\n",
      " 57%|█████▋    | 17/30 [23:33<16:47, 77.53s/it]Epoch 17\n",
      "Loss = 3.1222e-01, PNorm = 70.8198, GNorm = 0.7182, lr_0 = 2.7880e-04\n",
      "Loss = 3.3501e-01, PNorm = 70.9162, GNorm = 0.7383, lr_0 = 2.7396e-04\n",
      "Loss = 3.5278e-01, PNorm = 71.0177, GNorm = 0.8418, lr_0 = 2.6921e-04\n",
      "Loss = 3.2823e-01, PNorm = 71.1165, GNorm = 0.7610, lr_0 = 2.6454e-04\n",
      "Loss = 3.1260e-01, PNorm = 71.2007, GNorm = 0.8146, lr_0 = 2.5995e-04\n",
      "Validation auc = 0.783527\n",
      "Validation accuracy = 0.711149\n",
      " 60%|██████    | 18/30 [24:49<15:23, 76.98s/it]Epoch 18\n",
      "Loss = 3.0086e-01, PNorm = 71.2882, GNorm = 1.6048, lr_0 = 2.5544e-04\n",
      "Loss = 2.8245e-01, PNorm = 71.3760, GNorm = 0.8267, lr_0 = 2.5101e-04\n",
      "Loss = 2.8883e-01, PNorm = 71.4692, GNorm = 0.8827, lr_0 = 2.4666e-04\n",
      "Loss = 2.8348e-01, PNorm = 71.5453, GNorm = 0.6907, lr_0 = 2.4238e-04\n",
      "Validation auc = 0.789779\n",
      "Validation accuracy = 0.716216\n",
      " 63%|██████▎   | 19/30 [26:05<14:04, 76.79s/it]Epoch 19\n",
      "Loss = 2.1612e-01, PNorm = 71.6207, GNorm = 1.2080, lr_0 = 2.3776e-04\n",
      "Loss = 2.8145e-01, PNorm = 71.6978, GNorm = 1.1631, lr_0 = 2.3364e-04\n",
      "Loss = 2.4679e-01, PNorm = 71.7753, GNorm = 0.9480, lr_0 = 2.2958e-04\n",
      "Loss = 2.7494e-01, PNorm = 71.8527, GNorm = 1.2950, lr_0 = 2.2560e-04\n",
      "Loss = 2.8502e-01, PNorm = 71.9272, GNorm = 0.7813, lr_0 = 2.2169e-04\n",
      "Validation auc = 0.775257\n",
      "Validation accuracy = 0.704392\n",
      " 67%|██████▋   | 20/30 [27:22<12:46, 76.70s/it]Epoch 20\n",
      "Loss = 2.4232e-01, PNorm = 72.0094, GNorm = 0.8176, lr_0 = 2.1746e-04\n",
      "Loss = 2.2369e-01, PNorm = 72.0835, GNorm = 1.1127, lr_0 = 2.1369e-04\n",
      "Loss = 2.5889e-01, PNorm = 72.1555, GNorm = 1.1398, lr_0 = 2.0999e-04\n",
      "Loss = 2.5790e-01, PNorm = 72.2253, GNorm = 0.8462, lr_0 = 2.0634e-04\n",
      "Loss = 2.0624e-01, PNorm = 72.2930, GNorm = 0.7717, lr_0 = 2.0276e-04\n",
      "Validation auc = 0.765483\n",
      "Validation accuracy = 0.711149\n",
      " 70%|███████   | 21/30 [28:39<11:31, 76.78s/it]Epoch 21\n",
      "Loss = 2.0613e-01, PNorm = 72.3641, GNorm = 1.3150, lr_0 = 1.9890e-04\n",
      "Loss = 2.0946e-01, PNorm = 72.4297, GNorm = 1.5881, lr_0 = 1.9545e-04\n",
      "Loss = 2.1542e-01, PNorm = 72.4988, GNorm = 1.3488, lr_0 = 1.9206e-04\n",
      "Loss = 2.2688e-01, PNorm = 72.5570, GNorm = 1.1076, lr_0 = 1.8873e-04\n",
      "Loss = 2.1989e-01, PNorm = 72.6142, GNorm = 0.8050, lr_0 = 1.8545e-04\n",
      "Validation auc = 0.775876\n",
      "Validation accuracy = 0.707770\n",
      " 73%|███████▎  | 22/30 [29:56<10:15, 76.90s/it]Epoch 22\n",
      "Loss = 2.1004e-01, PNorm = 72.6780, GNorm = 1.4354, lr_0 = 1.8224e-04\n",
      "Loss = 1.9552e-01, PNorm = 72.7308, GNorm = 1.3284, lr_0 = 1.7908e-04\n",
      "Loss = 1.9328e-01, PNorm = 72.7823, GNorm = 1.5125, lr_0 = 1.7597e-04\n",
      "Loss = 2.1732e-01, PNorm = 72.8407, GNorm = 1.6646, lr_0 = 1.7292e-04\n",
      "Validation auc = 0.779283\n",
      "Validation accuracy = 0.714527\n",
      " 77%|███████▋  | 23/30 [31:12<08:56, 76.69s/it]Epoch 23\n",
      "Loss = 1.5532e-01, PNorm = 72.8976, GNorm = 1.5088, lr_0 = 1.6962e-04\n",
      "Loss = 1.6931e-01, PNorm = 72.9469, GNorm = 0.9958, lr_0 = 1.6668e-04\n",
      "Loss = 1.7748e-01, PNorm = 72.9930, GNorm = 1.7748, lr_0 = 1.6379e-04\n",
      "Loss = 2.1644e-01, PNorm = 73.0359, GNorm = 1.2002, lr_0 = 1.6095e-04\n",
      "Loss = 2.0854e-01, PNorm = 73.0840, GNorm = 2.0262, lr_0 = 1.5816e-04\n",
      "Validation auc = 0.770989\n",
      "Validation accuracy = 0.711149\n",
      " 80%|████████  | 24/30 [32:28<07:38, 76.38s/it]Epoch 24\n",
      "Loss = 1.4584e-01, PNorm = 73.1426, GNorm = 1.3417, lr_0 = 1.5514e-04\n",
      "Loss = 1.5425e-01, PNorm = 73.1881, GNorm = 0.9107, lr_0 = 1.5245e-04\n",
      "Loss = 1.6714e-01, PNorm = 73.2308, GNorm = 1.0090, lr_0 = 1.4981e-04\n",
      "Loss = 1.5423e-01, PNorm = 73.2699, GNorm = 0.6196, lr_0 = 1.4721e-04\n",
      "Loss = 1.6308e-01, PNorm = 73.3095, GNorm = 0.8656, lr_0 = 1.4466e-04\n",
      "Validation auc = 0.777304\n",
      "Validation accuracy = 0.719595\n",
      " 83%|████████▎ | 25/30 [33:44<06:21, 76.31s/it]Epoch 25\n",
      "Loss = 1.5801e-01, PNorm = 73.3468, GNorm = 1.1104, lr_0 = 1.4215e-04\n",
      "Loss = 1.2548e-01, PNorm = 73.3816, GNorm = 0.9278, lr_0 = 1.3968e-04\n",
      "Loss = 1.4613e-01, PNorm = 73.4164, GNorm = 2.0090, lr_0 = 1.3726e-04\n",
      "Loss = 1.7914e-01, PNorm = 73.4502, GNorm = 1.9522, lr_0 = 1.3488e-04\n",
      "Validation auc = 0.776891\n",
      "Validation accuracy = 0.716216\n",
      " 87%|████████▋ | 26/30 [35:01<05:06, 76.59s/it]Epoch 26\n",
      "Loss = 1.4261e-01, PNorm = 73.4868, GNorm = 1.3709, lr_0 = 1.3231e-04\n",
      "Loss = 1.3298e-01, PNorm = 73.5227, GNorm = 1.2017, lr_0 = 1.3001e-04\n",
      "Loss = 1.5156e-01, PNorm = 73.5583, GNorm = 1.0697, lr_0 = 1.2776e-04\n",
      "Loss = 1.3725e-01, PNorm = 73.5900, GNorm = 1.2876, lr_0 = 1.2554e-04\n",
      "Loss = 1.1769e-01, PNorm = 73.6149, GNorm = 0.7786, lr_0 = 1.2336e-04\n",
      "Validation auc = 0.771810\n",
      "Validation accuracy = 0.704392\n",
      " 90%|█████████ | 27/30 [36:18<03:50, 76.78s/it]Epoch 27\n",
      "Loss = 1.2662e-01, PNorm = 73.6474, GNorm = 1.7366, lr_0 = 1.2101e-04\n",
      "Loss = 1.3935e-01, PNorm = 73.6785, GNorm = 1.2197, lr_0 = 1.1891e-04\n",
      "Loss = 9.5022e-02, PNorm = 73.7070, GNorm = 0.7996, lr_0 = 1.1685e-04\n",
      "Loss = 1.1994e-01, PNorm = 73.7301, GNorm = 0.8295, lr_0 = 1.1482e-04\n",
      "Loss = 1.4689e-01, PNorm = 73.7564, GNorm = 0.8953, lr_0 = 1.1283e-04\n",
      "Validation auc = 0.776582\n",
      "Validation accuracy = 0.714527\n",
      " 93%|█████████▎| 28/30 [37:35<02:33, 76.79s/it]Epoch 28\n",
      "Loss = 9.0247e-02, PNorm = 73.7849, GNorm = 0.8649, lr_0 = 1.1068e-04\n",
      "Loss = 1.0167e-01, PNorm = 73.8094, GNorm = 1.0583, lr_0 = 1.0876e-04\n",
      "Loss = 1.2298e-01, PNorm = 73.8320, GNorm = 0.6753, lr_0 = 1.0687e-04\n",
      "Loss = 1.1957e-01, PNorm = 73.8534, GNorm = 0.4749, lr_0 = 1.0502e-04\n",
      "Loss = 1.3796e-01, PNorm = 73.8791, GNorm = 0.7289, lr_0 = 1.0320e-04\n",
      "Validation auc = 0.775498\n",
      "Validation accuracy = 0.697635\n",
      " 97%|█████████▋| 29/30 [38:52<01:16, 76.78s/it]Epoch 29\n",
      "Loss = 1.2738e-01, PNorm = 73.9039, GNorm = 1.4913, lr_0 = 1.0141e-04\n",
      "Loss = 1.1232e-01, PNorm = 73.9264, GNorm = 1.4986, lr_0 = 1.0000e-04\n",
      "Loss = 9.7789e-02, PNorm = 73.9480, GNorm = 0.9104, lr_0 = 1.0000e-04\n",
      "Loss = 1.0420e-01, PNorm = 73.9735, GNorm = 1.2225, lr_0 = 1.0000e-04\n",
      "Validation auc = 0.772733\n",
      "Validation accuracy = 0.711149\n",
      "100%|██████████| 30/30 [40:08<00:00, 80.29s/it]\n",
      "Model 2 best validation auc = 0.789779 on epoch 18\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Model 2 test auc = 0.745502                    \n",
      "Model 2 test accuracy = 0.679783\n",
      "Building model 3\n",
      "MoleculeModel(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (encoder): MPN(\n",
      "    (encoder): ModuleList(\n",
      "      (0): MPNEncoder(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act_func): ReLU()\n",
      "        (W_i): Linear(in_features=147, out_features=1700, bias=False)\n",
      "        (W_h): Linear(in_features=1700, out_features=1700, bias=False)\n",
      "        (W_o): Linear(in_features=1833, out_features=1700, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=1900, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 6,261,301\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 6.9787e-01, PNorm = 61.1402, GNorm = 1.7744, lr_0 = 2.0532e-04\n",
      "Loss = 6.9355e-01, PNorm = 61.1589, GNorm = 0.4100, lr_0 = 3.0106e-04\n",
      "Loss = 6.6804e-01, PNorm = 61.1887, GNorm = 0.8188, lr_0 = 3.9681e-04\n",
      "Loss = 6.7943e-01, PNorm = 61.2263, GNorm = 0.6947, lr_0 = 4.9255e-04\n",
      "Validation auc = 0.665512\n",
      "Validation accuracy = 0.614865\n",
      "  3%|▎         | 1/30 [01:17<37:30, 77.59s/it]Epoch 1\n",
      "Loss = 6.5842e-01, PNorm = 61.2796, GNorm = 0.4475, lr_0 = 5.9787e-04\n",
      "Loss = 6.7384e-01, PNorm = 61.3368, GNorm = 0.4813, lr_0 = 6.9362e-04\n",
      "Loss = 6.7496e-01, PNorm = 61.4069, GNorm = 1.0639, lr_0 = 7.8936e-04\n",
      "Loss = 6.5858e-01, PNorm = 61.4983, GNorm = 0.4327, lr_0 = 8.8511e-04\n",
      "Loss = 6.8435e-01, PNorm = 61.6210, GNorm = 0.4312, lr_0 = 9.8085e-04\n",
      "Validation auc = 0.673129\n",
      "Validation accuracy = 0.579392\n",
      "  7%|▋         | 2/30 [02:34<35:55, 77.00s/it]Epoch 2\n",
      "Loss = 6.8326e-01, PNorm = 61.8255, GNorm = 0.3021, lr_0 = 9.8438e-04\n",
      "Loss = 6.5544e-01, PNorm = 61.9842, GNorm = 0.3789, lr_0 = 9.6730e-04\n",
      "Loss = 6.7103e-01, PNorm = 62.1247, GNorm = 0.9910, lr_0 = 9.5052e-04\n",
      "Loss = 6.4887e-01, PNorm = 62.2443, GNorm = 0.3954, lr_0 = 9.3404e-04\n",
      "Loss = 6.5287e-01, PNorm = 62.3662, GNorm = 0.6935, lr_0 = 9.1784e-04\n",
      "Validation auc = 0.704101\n",
      "Validation accuracy = 0.641892\n",
      " 10%|█         | 3/30 [03:50<34:36, 76.89s/it]Epoch 3\n",
      "Loss = 6.0595e-01, PNorm = 62.5037, GNorm = 0.4417, lr_0 = 9.0034e-04\n",
      "Loss = 6.4567e-01, PNorm = 62.6227, GNorm = 0.4615, lr_0 = 8.8473e-04\n",
      "Loss = 6.3784e-01, PNorm = 62.7452, GNorm = 0.3221, lr_0 = 8.6938e-04\n",
      "Loss = 6.5548e-01, PNorm = 62.8761, GNorm = 0.7758, lr_0 = 8.5430e-04\n",
      "Validation auc = 0.711339\n",
      "Validation accuracy = 0.591216\n",
      " 13%|█▎        | 4/30 [05:07<33:17, 76.84s/it]Epoch 4\n",
      "Loss = 6.3429e-01, PNorm = 63.0394, GNorm = 0.3893, lr_0 = 8.3948e-04\n",
      "Loss = 6.3301e-01, PNorm = 63.1854, GNorm = 0.5287, lr_0 = 8.2492e-04\n",
      "Loss = 6.3385e-01, PNorm = 63.3338, GNorm = 1.5338, lr_0 = 8.1061e-04\n",
      "Loss = 6.0606e-01, PNorm = 63.4883, GNorm = 0.8149, lr_0 = 7.9656e-04\n",
      "Loss = 6.2675e-01, PNorm = 63.6074, GNorm = 0.4895, lr_0 = 7.8274e-04\n",
      "Validation auc = 0.738870\n",
      "Validation accuracy = 0.670608\n",
      " 17%|█▋        | 5/30 [06:24<32:01, 76.85s/it]Epoch 5\n",
      "Loss = 5.9606e-01, PNorm = 63.7175, GNorm = 0.7377, lr_0 = 7.6782e-04\n",
      "Loss = 6.0547e-01, PNorm = 63.8543, GNorm = 0.4465, lr_0 = 7.5450e-04\n",
      "Loss = 6.3175e-01, PNorm = 63.9695, GNorm = 0.4463, lr_0 = 7.4141e-04\n",
      "Loss = 6.1378e-01, PNorm = 64.0905, GNorm = 0.4504, lr_0 = 7.2855e-04\n",
      "Loss = 6.3214e-01, PNorm = 64.2025, GNorm = 0.5866, lr_0 = 7.1592e-04\n",
      "Validation auc = 0.740946\n",
      "Validation accuracy = 0.673986\n",
      " 20%|██        | 6/30 [07:41<30:42, 76.78s/it]Epoch 6\n",
      "Loss = 6.0159e-01, PNorm = 64.3456, GNorm = 0.4790, lr_0 = 7.0227e-04\n",
      "Loss = 5.7318e-01, PNorm = 64.4909, GNorm = 0.5038, lr_0 = 6.9009e-04\n",
      "Loss = 6.2793e-01, PNorm = 64.6107, GNorm = 0.3829, lr_0 = 6.7812e-04\n",
      "Loss = 5.9729e-01, PNorm = 64.7513, GNorm = 0.4795, lr_0 = 6.6636e-04\n",
      "Loss = 5.7648e-01, PNorm = 64.8631, GNorm = 0.8716, lr_0 = 6.5480e-04\n",
      "Loss = 5.3167e-01, PNorm = 64.8749, GNorm = 1.0552, lr_0 = 6.5366e-04\n",
      "Validation auc = 0.768110\n",
      "Validation accuracy = 0.692568\n",
      " 23%|██▎       | 7/30 [08:56<29:18, 76.44s/it]Epoch 7\n",
      "Loss = 5.5523e-01, PNorm = 65.0062, GNorm = 0.5865, lr_0 = 6.4232e-04\n",
      "Loss = 5.8465e-01, PNorm = 65.1227, GNorm = 1.0097, lr_0 = 6.3118e-04\n",
      "Loss = 5.6261e-01, PNorm = 65.2616, GNorm = 0.5754, lr_0 = 6.2023e-04\n",
      "Loss = 5.4577e-01, PNorm = 65.4171, GNorm = 0.5405, lr_0 = 6.0947e-04\n",
      "Validation auc = 0.773903\n",
      "Validation accuracy = 0.687500\n",
      " 27%|██▋       | 8/30 [10:12<27:58, 76.28s/it]Epoch 8\n",
      "Loss = 5.9719e-01, PNorm = 65.5634, GNorm = 1.4868, lr_0 = 5.9890e-04\n",
      "Loss = 5.9165e-01, PNorm = 65.7476, GNorm = 0.8533, lr_0 = 5.8851e-04\n",
      "Loss = 5.7577e-01, PNorm = 65.9049, GNorm = 0.6832, lr_0 = 5.7831e-04\n",
      "Loss = 5.7579e-01, PNorm = 66.0475, GNorm = 0.5946, lr_0 = 5.6828e-04\n",
      "Loss = 5.2826e-01, PNorm = 66.1897, GNorm = 0.8287, lr_0 = 5.5842e-04\n",
      "Validation auc = 0.768638\n",
      "Validation accuracy = 0.709459\n",
      " 30%|███       | 9/30 [11:29<26:42, 76.32s/it]Epoch 9\n",
      "Loss = 5.6105e-01, PNorm = 66.3573, GNorm = 0.4351, lr_0 = 5.4777e-04\n",
      "Loss = 4.9351e-01, PNorm = 66.5127, GNorm = 0.9805, lr_0 = 5.3827e-04\n",
      "Loss = 5.4584e-01, PNorm = 66.6483, GNorm = 0.9968, lr_0 = 5.2894e-04\n",
      "Loss = 5.3642e-01, PNorm = 66.7843, GNorm = 0.4272, lr_0 = 5.1976e-04\n",
      "Loss = 5.4268e-01, PNorm = 66.9246, GNorm = 0.8956, lr_0 = 5.1075e-04\n",
      "Validation auc = 0.793496\n",
      "Validation accuracy = 0.714527\n",
      " 33%|███▎      | 10/30 [12:45<25:27, 76.36s/it]Epoch 10\n",
      "Loss = 4.7897e-01, PNorm = 67.0656, GNorm = 0.4843, lr_0 = 5.0101e-04\n",
      "Loss = 4.6660e-01, PNorm = 67.2063, GNorm = 1.0684, lr_0 = 4.9232e-04\n",
      "Loss = 5.4315e-01, PNorm = 67.3331, GNorm = 0.6327, lr_0 = 4.8378e-04\n",
      "Loss = 4.9260e-01, PNorm = 67.4748, GNorm = 0.5178, lr_0 = 4.7539e-04\n",
      "Loss = 5.3469e-01, PNorm = 67.6126, GNorm = 1.3157, lr_0 = 4.6715e-04\n",
      "Validation auc = 0.783137\n",
      "Validation accuracy = 0.689189\n",
      " 37%|███▋      | 11/30 [14:02<24:11, 76.38s/it]Epoch 11\n",
      "Loss = 4.4411e-01, PNorm = 67.7612, GNorm = 0.7347, lr_0 = 4.5904e-04\n",
      "Loss = 4.6116e-01, PNorm = 67.9061, GNorm = 0.6622, lr_0 = 4.5108e-04\n",
      "Loss = 4.8998e-01, PNorm = 68.0503, GNorm = 1.0229, lr_0 = 4.4326e-04\n",
      "Loss = 4.9473e-01, PNorm = 68.1907, GNorm = 0.5906, lr_0 = 4.3557e-04\n",
      "Validation auc = 0.786957\n",
      "Validation accuracy = 0.707770\n",
      " 40%|████      | 12/30 [15:18<22:56, 76.46s/it]Epoch 12\n",
      "Loss = 3.7417e-01, PNorm = 68.3399, GNorm = 0.5332, lr_0 = 4.2727e-04\n",
      "Loss = 3.9757e-01, PNorm = 68.4915, GNorm = 1.2770, lr_0 = 4.1986e-04\n",
      "Loss = 4.2310e-01, PNorm = 68.6491, GNorm = 0.5508, lr_0 = 4.1257e-04\n",
      "Loss = 4.8138e-01, PNorm = 68.7977, GNorm = 0.9993, lr_0 = 4.0542e-04\n",
      "Loss = 4.8647e-01, PNorm = 68.9245, GNorm = 0.9840, lr_0 = 3.9839e-04\n",
      "Validation auc = 0.786303\n",
      "Validation accuracy = 0.706081\n",
      " 43%|████▎     | 13/30 [16:34<21:37, 76.35s/it]Epoch 13\n",
      "Loss = 4.4373e-01, PNorm = 69.0555, GNorm = 0.7591, lr_0 = 3.9079e-04\n",
      "Loss = 4.1326e-01, PNorm = 69.1891, GNorm = 0.7665, lr_0 = 3.8401e-04\n",
      "Loss = 3.8756e-01, PNorm = 69.3359, GNorm = 0.6739, lr_0 = 3.7735e-04\n",
      "Loss = 4.0779e-01, PNorm = 69.4870, GNorm = 0.9265, lr_0 = 3.7081e-04\n",
      "Loss = 4.3808e-01, PNorm = 69.6233, GNorm = 0.8540, lr_0 = 3.6438e-04\n",
      "Validation auc = 0.785099\n",
      "Validation accuracy = 0.694257\n",
      " 47%|████▋     | 14/30 [17:50<20:17, 76.09s/it]Epoch 14\n",
      "Loss = 3.7911e-01, PNorm = 69.7745, GNorm = 0.7153, lr_0 = 3.5743e-04\n",
      "Loss = 3.6859e-01, PNorm = 69.9000, GNorm = 0.9899, lr_0 = 3.5123e-04\n",
      "Loss = 4.4614e-01, PNorm = 70.0237, GNorm = 1.1134, lr_0 = 3.4514e-04\n",
      "Loss = 3.8567e-01, PNorm = 70.1440, GNorm = 1.1397, lr_0 = 3.3915e-04\n",
      "Validation auc = 0.789183\n",
      "Validation accuracy = 0.722973\n",
      " 50%|█████     | 15/30 [19:05<18:57, 75.82s/it]Epoch 15\n",
      "Loss = 3.5127e-01, PNorm = 70.2566, GNorm = 0.8612, lr_0 = 3.3327e-04\n",
      "Loss = 3.7548e-01, PNorm = 70.3742, GNorm = 0.6578, lr_0 = 3.2749e-04\n",
      "Loss = 3.1894e-01, PNorm = 70.4940, GNorm = 1.1576, lr_0 = 3.2181e-04\n",
      "Loss = 3.6047e-01, PNorm = 70.6115, GNorm = 1.1295, lr_0 = 3.1623e-04\n",
      "Loss = 3.9250e-01, PNorm = 70.7355, GNorm = 1.0937, lr_0 = 3.1074e-04\n",
      "Validation auc = 0.792601\n",
      "Validation accuracy = 0.721284\n",
      " 53%|█████▎    | 16/30 [20:21<17:42, 75.93s/it]Epoch 16\n",
      "Loss = 3.2861e-01, PNorm = 70.8593, GNorm = 0.8323, lr_0 = 3.0482e-04\n",
      "Loss = 3.3453e-01, PNorm = 70.9798, GNorm = 1.0118, lr_0 = 2.9953e-04\n",
      "Loss = 3.3269e-01, PNorm = 71.0886, GNorm = 0.6986, lr_0 = 2.9434e-04\n",
      "Loss = 3.3129e-01, PNorm = 71.1866, GNorm = 0.8776, lr_0 = 2.8923e-04\n",
      "Loss = 3.0638e-01, PNorm = 71.2855, GNorm = 1.3084, lr_0 = 2.8422e-04\n",
      "Validation auc = 0.793094\n",
      "Validation accuracy = 0.699324\n",
      " 57%|█████▋    | 17/30 [21:38<16:29, 76.14s/it]Epoch 17\n",
      "Loss = 3.0507e-01, PNorm = 71.4034, GNorm = 1.0213, lr_0 = 2.7880e-04\n",
      "Loss = 2.6823e-01, PNorm = 71.5095, GNorm = 0.9545, lr_0 = 2.7396e-04\n",
      "Loss = 2.9406e-01, PNorm = 71.6016, GNorm = 0.6431, lr_0 = 2.6921e-04\n",
      "Loss = 3.1145e-01, PNorm = 71.6897, GNorm = 0.8762, lr_0 = 2.6454e-04\n",
      "Loss = 3.1249e-01, PNorm = 71.7800, GNorm = 0.9258, lr_0 = 2.5995e-04\n",
      "Validation auc = 0.780602\n",
      "Validation accuracy = 0.719595\n",
      " 60%|██████    | 18/30 [22:55<15:15, 76.32s/it]Epoch 18\n",
      "Loss = 2.5226e-01, PNorm = 71.8664, GNorm = 1.1907, lr_0 = 2.5544e-04\n",
      "Loss = 2.7737e-01, PNorm = 71.9505, GNorm = 1.8543, lr_0 = 2.5101e-04\n",
      "Loss = 2.6360e-01, PNorm = 72.0439, GNorm = 1.4034, lr_0 = 2.4666e-04\n",
      "Loss = 3.3329e-01, PNorm = 72.1404, GNorm = 1.2387, lr_0 = 2.4238e-04\n",
      "Validation auc = 0.796719\n",
      "Validation accuracy = 0.729730\n",
      " 63%|██████▎   | 19/30 [24:12<14:02, 76.60s/it]Epoch 19\n",
      "Loss = 2.4475e-01, PNorm = 72.2359, GNorm = 1.1187, lr_0 = 2.3776e-04\n",
      "Loss = 2.5355e-01, PNorm = 72.3201, GNorm = 1.1381, lr_0 = 2.3364e-04\n",
      "Loss = 2.5256e-01, PNorm = 72.3941, GNorm = 0.7978, lr_0 = 2.2958e-04\n",
      "Loss = 2.3866e-01, PNorm = 72.4665, GNorm = 1.2472, lr_0 = 2.2560e-04\n",
      "Loss = 2.6178e-01, PNorm = 72.5335, GNorm = 1.5863, lr_0 = 2.2169e-04\n",
      "Validation auc = 0.772400\n",
      "Validation accuracy = 0.704392\n",
      " 67%|██████▋   | 20/30 [25:28<12:43, 76.33s/it]Epoch 20\n",
      "Loss = 1.9400e-01, PNorm = 72.6147, GNorm = 0.8061, lr_0 = 2.1746e-04\n",
      "Loss = 2.0943e-01, PNorm = 72.6939, GNorm = 1.3543, lr_0 = 2.1369e-04\n",
      "Loss = 2.4808e-01, PNorm = 72.7604, GNorm = 1.4702, lr_0 = 2.0999e-04\n",
      "Loss = 2.0593e-01, PNorm = 72.8209, GNorm = 1.7603, lr_0 = 2.0634e-04\n",
      "Loss = 2.3889e-01, PNorm = 72.8874, GNorm = 0.9409, lr_0 = 2.0276e-04\n",
      "Validation auc = 0.790313\n",
      "Validation accuracy = 0.706081\n",
      " 70%|███████   | 21/30 [26:44<11:28, 76.50s/it]Epoch 21\n",
      "Loss = 1.7689e-01, PNorm = 72.9621, GNorm = 1.4339, lr_0 = 1.9890e-04\n",
      "Loss = 1.8605e-01, PNorm = 73.0303, GNorm = 1.0948, lr_0 = 1.9545e-04\n",
      "Loss = 2.0073e-01, PNorm = 73.0949, GNorm = 1.0753, lr_0 = 1.9206e-04\n",
      "Loss = 2.1504e-01, PNorm = 73.1546, GNorm = 1.0653, lr_0 = 1.8873e-04\n",
      "Loss = 1.9514e-01, PNorm = 73.2031, GNorm = 1.8392, lr_0 = 1.8545e-04\n",
      "Validation auc = 0.790181\n",
      "Validation accuracy = 0.722973\n",
      " 73%|███████▎  | 22/30 [28:01<10:11, 76.43s/it]Epoch 22\n",
      "Loss = 1.5991e-01, PNorm = 73.2541, GNorm = 0.9588, lr_0 = 1.8224e-04\n",
      "Loss = 1.6951e-01, PNorm = 73.3072, GNorm = 1.5443, lr_0 = 1.7908e-04\n",
      "Loss = 1.7710e-01, PNorm = 73.3583, GNorm = 1.2428, lr_0 = 1.7597e-04\n",
      "Loss = 1.7050e-01, PNorm = 73.4098, GNorm = 1.7565, lr_0 = 1.7292e-04\n",
      "Validation auc = 0.789160\n",
      "Validation accuracy = 0.707770\n",
      " 77%|███████▋  | 23/30 [29:17<08:55, 76.50s/it]Epoch 23\n",
      "Loss = 1.4929e-01, PNorm = 73.4595, GNorm = 1.1074, lr_0 = 1.6962e-04\n",
      "Loss = 1.5761e-01, PNorm = 73.5037, GNorm = 1.0082, lr_0 = 1.6668e-04\n",
      "Loss = 1.5525e-01, PNorm = 73.5465, GNorm = 1.0263, lr_0 = 1.6379e-04\n",
      "Loss = 1.3128e-01, PNorm = 73.5932, GNorm = 1.2085, lr_0 = 1.6095e-04\n",
      "Loss = 1.8309e-01, PNorm = 73.6360, GNorm = 0.7368, lr_0 = 1.5816e-04\n",
      "Validation auc = 0.779547\n",
      "Validation accuracy = 0.702703\n",
      " 80%|████████  | 24/30 [30:34<07:39, 76.57s/it]Epoch 24\n",
      "Loss = 1.4451e-01, PNorm = 73.6881, GNorm = 0.9303, lr_0 = 1.5514e-04\n",
      "Loss = 1.4804e-01, PNorm = 73.7307, GNorm = 1.1024, lr_0 = 1.5245e-04\n",
      "Loss = 1.5138e-01, PNorm = 73.7684, GNorm = 2.3324, lr_0 = 1.4981e-04\n",
      "Loss = 1.3986e-01, PNorm = 73.8089, GNorm = 1.6169, lr_0 = 1.4721e-04\n",
      "Loss = 1.7527e-01, PNorm = 73.8464, GNorm = 1.2904, lr_0 = 1.4466e-04\n",
      "Validation auc = 0.772980\n",
      "Validation accuracy = 0.692568\n",
      " 83%|████████▎ | 25/30 [31:51<06:23, 76.62s/it]Epoch 25\n",
      "Loss = 1.5059e-01, PNorm = 73.8887, GNorm = 1.2781, lr_0 = 1.4215e-04\n",
      "Loss = 1.2590e-01, PNorm = 73.9257, GNorm = 4.4708, lr_0 = 1.3968e-04\n",
      "Loss = 1.3980e-01, PNorm = 73.9673, GNorm = 2.0901, lr_0 = 1.3726e-04\n",
      "Loss = 1.9440e-01, PNorm = 74.0047, GNorm = 1.7179, lr_0 = 1.3488e-04\n",
      "Validation auc = 0.782415\n",
      "Validation accuracy = 0.711149\n",
      " 87%|████████▋ | 26/30 [33:07<05:06, 76.53s/it]Epoch 26\n",
      "Loss = 9.1276e-02, PNorm = 74.0431, GNorm = 0.7070, lr_0 = 1.3231e-04\n",
      "Loss = 1.1126e-01, PNorm = 74.0755, GNorm = 1.6241, lr_0 = 1.3001e-04\n",
      "Loss = 1.3078e-01, PNorm = 74.1045, GNorm = 0.8040, lr_0 = 1.2776e-04\n",
      "Loss = 1.1761e-01, PNorm = 74.1332, GNorm = 1.1038, lr_0 = 1.2554e-04\n",
      "Loss = 1.1684e-01, PNorm = 74.1619, GNorm = 1.3193, lr_0 = 1.2336e-04\n",
      "Validation auc = 0.778130\n",
      "Validation accuracy = 0.701014\n",
      " 90%|█████████ | 27/30 [34:25<03:50, 76.77s/it]Epoch 27\n",
      "Loss = 1.0540e-01, PNorm = 74.1934, GNorm = 0.8591, lr_0 = 1.2101e-04\n",
      "Loss = 1.1338e-01, PNorm = 74.2213, GNorm = 0.7172, lr_0 = 1.1891e-04\n",
      "Loss = 1.1113e-01, PNorm = 74.2468, GNorm = 0.6590, lr_0 = 1.1685e-04\n",
      "Loss = 1.1602e-01, PNorm = 74.2729, GNorm = 0.7715, lr_0 = 1.1482e-04\n",
      "Loss = 8.9013e-02, PNorm = 74.2957, GNorm = 0.7555, lr_0 = 1.1283e-04\n",
      "Validation auc = 0.777115\n",
      "Validation accuracy = 0.707770\n",
      " 93%|█████████▎| 28/30 [35:40<02:33, 76.50s/it]Epoch 28\n",
      "Loss = 9.8457e-02, PNorm = 74.3197, GNorm = 1.1368, lr_0 = 1.1068e-04\n",
      "Loss = 9.9713e-02, PNorm = 74.3445, GNorm = 0.6524, lr_0 = 1.0876e-04\n",
      "Loss = 1.0947e-01, PNorm = 74.3668, GNorm = 1.0957, lr_0 = 1.0687e-04\n",
      "Loss = 1.1356e-01, PNorm = 74.3882, GNorm = 0.6752, lr_0 = 1.0502e-04\n",
      "Loss = 1.1520e-01, PNorm = 74.4098, GNorm = 0.7438, lr_0 = 1.0320e-04\n",
      "Validation auc = 0.776151\n",
      "Validation accuracy = 0.701014\n",
      " 97%|█████████▋| 29/30 [36:56<01:16, 76.35s/it]Epoch 29\n",
      "Loss = 1.0620e-01, PNorm = 74.4355, GNorm = 1.6466, lr_0 = 1.0141e-04\n",
      "Loss = 9.4778e-02, PNorm = 74.4595, GNorm = 0.8283, lr_0 = 1.0000e-04\n",
      "Loss = 9.6466e-02, PNorm = 74.4815, GNorm = 1.9787, lr_0 = 1.0000e-04\n",
      "Loss = 1.0821e-01, PNorm = 74.5058, GNorm = 1.5130, lr_0 = 1.0000e-04\n",
      "Validation auc = 0.773238\n",
      "Validation accuracy = 0.704392\n",
      "100%|██████████| 30/30 [38:13<00:00, 76.46s/it]\n",
      "Model 3 best validation auc = 0.796719 on epoch 18\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Model 3 test auc = 0.730465                    \n",
      "Model 3 test accuracy = 0.658073\n",
      "Building model 4\n",
      "MoleculeModel(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (encoder): MPN(\n",
      "    (encoder): ModuleList(\n",
      "      (0): MPNEncoder(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act_func): ReLU()\n",
      "        (W_i): Linear(in_features=147, out_features=1700, bias=False)\n",
      "        (W_h): Linear(in_features=1700, out_features=1700, bias=False)\n",
      "        (W_o): Linear(in_features=1833, out_features=1700, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=1900, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 6,261,301\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 7.1866e-01, PNorm = 61.1662, GNorm = 3.1661, lr_0 = 2.0532e-04\n",
      "Loss = 7.0119e-01, PNorm = 61.1843, GNorm = 1.0827, lr_0 = 3.0106e-04\n",
      "Loss = 6.7392e-01, PNorm = 61.2112, GNorm = 0.4162, lr_0 = 3.9681e-04\n",
      "Loss = 6.8623e-01, PNorm = 61.2429, GNorm = 0.4404, lr_0 = 4.9255e-04\n",
      "Validation auc = 0.649647\n",
      "Validation accuracy = 0.538851\n",
      "  3%|▎         | 1/30 [01:18<38:10, 78.98s/it]Epoch 1\n",
      "Loss = 6.8163e-01, PNorm = 61.2890, GNorm = 0.6136, lr_0 = 5.9787e-04\n",
      "Loss = 6.7596e-01, PNorm = 61.3466, GNorm = 0.8701, lr_0 = 6.9362e-04\n",
      "Loss = 6.8108e-01, PNorm = 61.4164, GNorm = 0.4795, lr_0 = 7.8936e-04\n",
      "Loss = 6.5981e-01, PNorm = 61.5160, GNorm = 0.3662, lr_0 = 8.8511e-04\n",
      "Loss = 6.6088e-01, PNorm = 61.6432, GNorm = 0.3908, lr_0 = 9.8085e-04\n",
      "Validation auc = 0.664686\n",
      "Validation accuracy = 0.576014\n",
      "  7%|▋         | 2/30 [02:36<36:30, 78.23s/it]Epoch 2\n",
      "Loss = 6.4119e-01, PNorm = 61.8312, GNorm = 0.5646, lr_0 = 9.8438e-04\n",
      "Loss = 6.6623e-01, PNorm = 62.0005, GNorm = 0.4567, lr_0 = 9.6730e-04\n",
      "Loss = 6.8110e-01, PNorm = 62.1313, GNorm = 0.6013, lr_0 = 9.5052e-04\n",
      "Loss = 6.5241e-01, PNorm = 62.2538, GNorm = 0.3621, lr_0 = 9.3404e-04\n",
      "Loss = 6.5870e-01, PNorm = 62.3628, GNorm = 0.6496, lr_0 = 9.1784e-04\n",
      "Validation auc = 0.689418\n",
      "Validation accuracy = 0.587838\n",
      " 10%|█         | 3/30 [03:53<34:52, 77.49s/it]Epoch 3\n",
      "Loss = 6.5982e-01, PNorm = 62.4643, GNorm = 0.3502, lr_0 = 9.0034e-04\n",
      "Loss = 6.5001e-01, PNorm = 62.5798, GNorm = 0.4138, lr_0 = 8.8473e-04\n",
      "Loss = 6.3746e-01, PNorm = 62.7076, GNorm = 0.9293, lr_0 = 8.6938e-04\n",
      "Loss = 6.2419e-01, PNorm = 62.8600, GNorm = 0.6834, lr_0 = 8.5430e-04\n",
      "Validation auc = 0.703757\n",
      "Validation accuracy = 0.628378\n",
      " 13%|█▎        | 4/30 [05:09<33:17, 76.84s/it]Epoch 4\n",
      "Loss = 6.2430e-01, PNorm = 62.9748, GNorm = 0.3750, lr_0 = 8.3948e-04\n",
      "Loss = 6.1180e-01, PNorm = 63.0977, GNorm = 0.6612, lr_0 = 8.2492e-04\n",
      "Loss = 6.1408e-01, PNorm = 63.2192, GNorm = 0.4260, lr_0 = 8.1061e-04\n",
      "Loss = 6.5105e-01, PNorm = 63.3452, GNorm = 0.5116, lr_0 = 7.9656e-04\n",
      "Loss = 6.2694e-01, PNorm = 63.5023, GNorm = 1.0338, lr_0 = 7.8274e-04\n",
      "Validation auc = 0.740797\n",
      "Validation accuracy = 0.668919\n",
      " 17%|█▋        | 5/30 [06:25<31:53, 76.56s/it]Epoch 5\n",
      "Loss = 6.0800e-01, PNorm = 63.6472, GNorm = 0.5774, lr_0 = 7.6782e-04\n",
      "Loss = 6.1430e-01, PNorm = 63.7788, GNorm = 0.4399, lr_0 = 7.5450e-04\n",
      "Loss = 6.1070e-01, PNorm = 63.8950, GNorm = 0.4110, lr_0 = 7.4141e-04\n",
      "Loss = 5.7906e-01, PNorm = 64.0499, GNorm = 0.7658, lr_0 = 7.2855e-04\n",
      "Loss = 6.3674e-01, PNorm = 64.1832, GNorm = 0.8083, lr_0 = 7.1592e-04\n",
      "Validation auc = 0.742518\n",
      "Validation accuracy = 0.662162\n",
      " 20%|██        | 6/30 [07:42<30:42, 76.76s/it]Epoch 6\n",
      "Loss = 6.1909e-01, PNorm = 64.3177, GNorm = 1.0576, lr_0 = 7.0227e-04\n",
      "Loss = 5.8407e-01, PNorm = 64.4583, GNorm = 0.4345, lr_0 = 6.9009e-04\n",
      "Loss = 5.7179e-01, PNorm = 64.5903, GNorm = 0.6545, lr_0 = 6.7812e-04\n",
      "Loss = 6.0102e-01, PNorm = 64.7155, GNorm = 0.5047, lr_0 = 6.6636e-04\n",
      "Loss = 5.9384e-01, PNorm = 64.8412, GNorm = 0.5780, lr_0 = 6.5480e-04\n",
      "Loss = 5.0435e-01, PNorm = 64.8542, GNorm = 0.7841, lr_0 = 6.5366e-04\n",
      "Validation auc = 0.759713\n",
      "Validation accuracy = 0.706081\n",
      " 23%|██▎       | 7/30 [08:58<29:24, 76.71s/it]Epoch 7\n",
      "Loss = 5.7070e-01, PNorm = 65.0141, GNorm = 0.6189, lr_0 = 6.4232e-04\n",
      "Loss = 5.7436e-01, PNorm = 65.1699, GNorm = 0.9604, lr_0 = 6.3118e-04\n",
      "Loss = 5.5397e-01, PNorm = 65.3299, GNorm = 0.5586, lr_0 = 6.2023e-04\n",
      "Loss = 5.5880e-01, PNorm = 65.4764, GNorm = 0.5646, lr_0 = 6.0947e-04\n",
      "Validation auc = 0.770072\n",
      "Validation accuracy = 0.707770\n",
      " 27%|██▋       | 8/30 [10:16<28:11, 76.91s/it]Epoch 8\n",
      "Loss = 5.6012e-01, PNorm = 65.6096, GNorm = 0.4680, lr_0 = 5.9890e-04\n",
      "Loss = 6.1807e-01, PNorm = 65.7626, GNorm = 0.9377, lr_0 = 5.8851e-04\n",
      "Loss = 5.5356e-01, PNorm = 65.9062, GNorm = 0.6363, lr_0 = 5.7831e-04\n",
      "Loss = 5.3478e-01, PNorm = 66.0380, GNorm = 0.7981, lr_0 = 5.6828e-04\n",
      "Loss = 5.2797e-01, PNorm = 66.1775, GNorm = 0.4222, lr_0 = 5.5842e-04\n",
      "Validation auc = 0.774305\n",
      "Validation accuracy = 0.709459\n",
      " 30%|███       | 9/30 [11:33<26:54, 76.89s/it]Epoch 9\n",
      "Loss = 5.4102e-01, PNorm = 66.3520, GNorm = 1.4270, lr_0 = 5.4777e-04\n",
      "Loss = 5.2184e-01, PNorm = 66.5249, GNorm = 1.0289, lr_0 = 5.3827e-04\n",
      "Loss = 5.2827e-01, PNorm = 66.6865, GNorm = 0.8489, lr_0 = 5.2894e-04\n",
      "Loss = 5.7179e-01, PNorm = 66.8293, GNorm = 0.4953, lr_0 = 5.1976e-04\n",
      "Loss = 5.2355e-01, PNorm = 66.9732, GNorm = 0.9620, lr_0 = 5.1075e-04\n",
      "Validation auc = 0.773972\n",
      "Validation accuracy = 0.695946\n",
      " 33%|███▎      | 10/30 [12:49<25:31, 76.59s/it]Epoch 10\n",
      "Loss = 4.8611e-01, PNorm = 67.1337, GNorm = 0.9379, lr_0 = 5.0101e-04\n",
      "Loss = 4.8103e-01, PNorm = 67.2968, GNorm = 0.5543, lr_0 = 4.9232e-04\n",
      "Loss = 5.1616e-01, PNorm = 67.4471, GNorm = 0.9553, lr_0 = 4.8378e-04\n",
      "Loss = 5.1463e-01, PNorm = 67.5898, GNorm = 1.0898, lr_0 = 4.7539e-04\n",
      "Loss = 4.9930e-01, PNorm = 67.7299, GNorm = 1.0760, lr_0 = 4.6715e-04\n",
      "Validation auc = 0.768351\n",
      "Validation accuracy = 0.687500\n",
      " 37%|███▋      | 11/30 [14:04<24:07, 76.20s/it]Epoch 11\n",
      "Loss = 4.7195e-01, PNorm = 67.8841, GNorm = 0.7547, lr_0 = 4.5904e-04\n",
      "Loss = 4.3369e-01, PNorm = 68.0517, GNorm = 1.0382, lr_0 = 4.5108e-04\n",
      "Loss = 4.6586e-01, PNorm = 68.2199, GNorm = 0.7125, lr_0 = 4.4326e-04\n",
      "Loss = 5.2198e-01, PNorm = 68.3739, GNorm = 0.6601, lr_0 = 4.3557e-04\n",
      "Validation auc = 0.785053\n",
      "Validation accuracy = 0.706081\n",
      " 40%|████      | 12/30 [15:20<22:49, 76.07s/it]Epoch 12\n",
      "Loss = 4.4374e-01, PNorm = 68.5270, GNorm = 0.5938, lr_0 = 4.2727e-04\n",
      "Loss = 4.4238e-01, PNorm = 68.6669, GNorm = 0.7030, lr_0 = 4.1986e-04\n",
      "Loss = 4.7197e-01, PNorm = 68.8086, GNorm = 0.9108, lr_0 = 4.1257e-04\n",
      "Loss = 4.6317e-01, PNorm = 68.9625, GNorm = 1.1759, lr_0 = 4.0542e-04\n",
      "Loss = 4.3246e-01, PNorm = 69.1059, GNorm = 0.9246, lr_0 = 3.9839e-04\n",
      "Validation auc = 0.784479\n",
      "Validation accuracy = 0.716216\n",
      " 43%|████▎     | 13/30 [16:36<21:36, 76.25s/it]Epoch 13\n",
      "Loss = 3.7698e-01, PNorm = 69.2383, GNorm = 0.5077, lr_0 = 3.9079e-04\n",
      "Loss = 4.5436e-01, PNorm = 69.3697, GNorm = 0.8596, lr_0 = 3.8401e-04\n",
      "Loss = 4.0308e-01, PNorm = 69.4989, GNorm = 0.9348, lr_0 = 3.7735e-04\n",
      "Loss = 4.0064e-01, PNorm = 69.6206, GNorm = 0.9636, lr_0 = 3.7081e-04\n",
      "Loss = 4.3524e-01, PNorm = 69.7387, GNorm = 1.3363, lr_0 = 3.6438e-04\n",
      "Validation auc = 0.778905\n",
      "Validation accuracy = 0.689189\n",
      " 47%|████▋     | 14/30 [17:53<20:22, 76.40s/it]Epoch 14\n",
      "Loss = 4.0786e-01, PNorm = 69.8835, GNorm = 0.7042, lr_0 = 3.5743e-04\n",
      "Loss = 3.9994e-01, PNorm = 70.0130, GNorm = 1.0680, lr_0 = 3.5123e-04\n",
      "Loss = 4.1401e-01, PNorm = 70.1512, GNorm = 1.3002, lr_0 = 3.4514e-04\n",
      "Loss = 3.6362e-01, PNorm = 70.2876, GNorm = 0.8120, lr_0 = 3.3915e-04\n",
      "Validation auc = 0.787978\n",
      "Validation accuracy = 0.716216\n",
      " 50%|█████     | 15/30 [19:10<19:08, 76.55s/it]Epoch 15\n",
      "Loss = 3.8076e-01, PNorm = 70.4163, GNorm = 0.6718, lr_0 = 3.3327e-04\n",
      "Loss = 3.4272e-01, PNorm = 70.5582, GNorm = 1.0449, lr_0 = 3.2749e-04\n",
      "Loss = 3.5053e-01, PNorm = 70.6887, GNorm = 0.9642, lr_0 = 3.2181e-04\n",
      "Loss = 3.5830e-01, PNorm = 70.7957, GNorm = 1.7270, lr_0 = 3.1623e-04\n",
      "Loss = 3.6601e-01, PNorm = 70.9169, GNorm = 1.2333, lr_0 = 3.1074e-04\n",
      "Validation auc = 0.769693\n",
      "Validation accuracy = 0.704392\n",
      " 53%|█████▎    | 16/30 [20:26<17:49, 76.41s/it]Epoch 16\n",
      "Loss = 2.9375e-01, PNorm = 71.0313, GNorm = 0.6787, lr_0 = 3.0482e-04\n",
      "Loss = 3.4246e-01, PNorm = 71.1391, GNorm = 1.1075, lr_0 = 2.9953e-04\n",
      "Loss = 3.0507e-01, PNorm = 71.2439, GNorm = 0.6947, lr_0 = 2.9434e-04\n",
      "Loss = 3.7007e-01, PNorm = 71.3630, GNorm = 1.3113, lr_0 = 2.8923e-04\n",
      "Loss = 3.4057e-01, PNorm = 71.4744, GNorm = 0.7074, lr_0 = 2.8422e-04\n",
      "Validation auc = 0.779547\n",
      "Validation accuracy = 0.699324\n",
      " 57%|█████▋    | 17/30 [21:42<16:30, 76.22s/it]Epoch 17\n",
      "Loss = 3.0346e-01, PNorm = 71.5773, GNorm = 1.7156, lr_0 = 2.7880e-04\n",
      "Loss = 3.2136e-01, PNorm = 71.6707, GNorm = 1.1569, lr_0 = 2.7396e-04\n",
      "Loss = 3.0893e-01, PNorm = 71.7631, GNorm = 1.1714, lr_0 = 2.6921e-04\n",
      "Loss = 2.8820e-01, PNorm = 71.8630, GNorm = 1.4709, lr_0 = 2.6454e-04\n",
      "Loss = 2.9891e-01, PNorm = 71.9567, GNorm = 1.1254, lr_0 = 2.5995e-04\n",
      "Validation auc = 0.773708\n",
      "Validation accuracy = 0.706081\n",
      " 60%|██████    | 18/30 [22:58<15:13, 76.15s/it]Epoch 18\n",
      "Loss = 2.7911e-01, PNorm = 72.0463, GNorm = 0.9059, lr_0 = 2.5544e-04\n",
      "Loss = 2.4443e-01, PNorm = 72.1278, GNorm = 0.7006, lr_0 = 2.5101e-04\n",
      "Loss = 2.7944e-01, PNorm = 72.2032, GNorm = 1.1202, lr_0 = 2.4666e-04\n",
      "Loss = 2.4686e-01, PNorm = 72.2879, GNorm = 1.6024, lr_0 = 2.4238e-04\n",
      "Validation auc = 0.781004\n",
      "Validation accuracy = 0.711149\n",
      " 63%|██████▎   | 19/30 [24:15<13:59, 76.34s/it]Epoch 19\n",
      "Loss = 2.6100e-01, PNorm = 72.3803, GNorm = 1.3614, lr_0 = 2.3776e-04\n",
      "Loss = 2.7583e-01, PNorm = 72.4747, GNorm = 1.0401, lr_0 = 2.3364e-04\n",
      "Loss = 2.6587e-01, PNorm = 72.5735, GNorm = 1.0459, lr_0 = 2.2958e-04\n",
      "Loss = 2.4924e-01, PNorm = 72.6561, GNorm = 0.7529, lr_0 = 2.2560e-04\n",
      "Loss = 2.7327e-01, PNorm = 72.7236, GNorm = 1.7666, lr_0 = 2.2169e-04\n",
      "Validation auc = 0.773152\n",
      "Validation accuracy = 0.704392\n",
      " 67%|██████▋   | 20/30 [25:31<12:44, 76.43s/it]Epoch 20\n",
      "Loss = 2.2525e-01, PNorm = 72.8012, GNorm = 0.7953, lr_0 = 2.1746e-04\n",
      "Loss = 2.3779e-01, PNorm = 72.8718, GNorm = 0.9690, lr_0 = 2.1369e-04\n",
      "Loss = 2.0686e-01, PNorm = 72.9372, GNorm = 1.1006, lr_0 = 2.0999e-04\n",
      "Loss = 2.2430e-01, PNorm = 72.9964, GNorm = 1.5039, lr_0 = 2.0634e-04\n",
      "Loss = 2.4839e-01, PNorm = 73.0578, GNorm = 1.3652, lr_0 = 2.0276e-04\n",
      "Validation auc = 0.767468\n",
      "Validation accuracy = 0.699324\n",
      " 70%|███████   | 21/30 [26:48<11:29, 76.58s/it]Epoch 21\n",
      "Loss = 2.0850e-01, PNorm = 73.1238, GNorm = 1.1581, lr_0 = 1.9890e-04\n",
      "Loss = 1.8436e-01, PNorm = 73.1845, GNorm = 1.1199, lr_0 = 1.9545e-04\n",
      "Loss = 2.1214e-01, PNorm = 73.2414, GNorm = 1.1587, lr_0 = 1.9206e-04\n",
      "Loss = 2.4426e-01, PNorm = 73.2978, GNorm = 1.4797, lr_0 = 1.8873e-04\n",
      "Loss = 1.9007e-01, PNorm = 73.3608, GNorm = 1.7245, lr_0 = 1.8545e-04\n",
      "Validation auc = 0.769848\n",
      "Validation accuracy = 0.702703\n",
      " 73%|███████▎  | 22/30 [28:05<10:13, 76.67s/it]Epoch 22\n",
      "Loss = 1.6278e-01, PNorm = 73.4108, GNorm = 1.1825, lr_0 = 1.8224e-04\n",
      "Loss = 1.9053e-01, PNorm = 73.4676, GNorm = 1.3696, lr_0 = 1.7908e-04\n",
      "Loss = 2.0400e-01, PNorm = 73.5195, GNorm = 0.8421, lr_0 = 1.7597e-04\n",
      "Loss = 1.9730e-01, PNorm = 73.5767, GNorm = 1.0462, lr_0 = 1.7292e-04\n",
      "Validation auc = 0.772148\n",
      "Validation accuracy = 0.701014\n",
      " 77%|███████▋  | 23/30 [29:21<08:55, 76.49s/it]Epoch 23\n",
      "Loss = 1.6787e-01, PNorm = 73.6317, GNorm = 0.4958, lr_0 = 1.6962e-04\n",
      "Loss = 1.4174e-01, PNorm = 73.6785, GNorm = 0.8103, lr_0 = 1.6668e-04\n",
      "Loss = 1.5111e-01, PNorm = 73.7294, GNorm = 0.6414, lr_0 = 1.6379e-04\n",
      "Loss = 1.7021e-01, PNorm = 73.7778, GNorm = 2.0077, lr_0 = 1.6095e-04\n",
      "Loss = 1.7298e-01, PNorm = 73.8274, GNorm = 1.7668, lr_0 = 1.5816e-04\n",
      "Validation auc = 0.775584\n",
      "Validation accuracy = 0.712838\n",
      " 80%|████████  | 24/30 [30:37<07:38, 76.36s/it]Epoch 24\n",
      "Loss = 1.3800e-01, PNorm = 73.8724, GNorm = 1.1012, lr_0 = 1.5514e-04\n",
      "Loss = 1.4137e-01, PNorm = 73.9132, GNorm = 1.3313, lr_0 = 1.5245e-04\n",
      "Loss = 1.6701e-01, PNorm = 73.9563, GNorm = 1.3641, lr_0 = 1.4981e-04\n",
      "Loss = 1.6641e-01, PNorm = 74.0006, GNorm = 1.5443, lr_0 = 1.4721e-04\n",
      "Loss = 1.7470e-01, PNorm = 74.0472, GNorm = 1.7336, lr_0 = 1.4466e-04\n",
      "Validation auc = 0.769429\n",
      "Validation accuracy = 0.707770\n",
      " 83%|████████▎ | 25/30 [31:53<06:20, 76.14s/it]Epoch 25\n",
      "Loss = 1.2402e-01, PNorm = 74.0895, GNorm = 1.1475, lr_0 = 1.4215e-04\n",
      "Loss = 1.5074e-01, PNorm = 74.1336, GNorm = 1.0649, lr_0 = 1.3968e-04\n",
      "Loss = 1.2614e-01, PNorm = 74.1699, GNorm = 1.3558, lr_0 = 1.3726e-04\n",
      "Loss = 1.5488e-01, PNorm = 74.2057, GNorm = 1.7218, lr_0 = 1.3488e-04\n",
      "Validation auc = 0.766573\n",
      "Validation accuracy = 0.694257\n",
      " 87%|████████▋ | 26/30 [33:09<05:04, 76.23s/it]Epoch 26\n",
      "Loss = 8.5016e-02, PNorm = 74.2399, GNorm = 0.8604, lr_0 = 1.3231e-04\n",
      "Loss = 1.3421e-01, PNorm = 74.2726, GNorm = 1.5267, lr_0 = 1.3001e-04\n",
      "Loss = 1.2466e-01, PNorm = 74.3058, GNorm = 1.5970, lr_0 = 1.2776e-04\n",
      "Loss = 1.2750e-01, PNorm = 74.3379, GNorm = 1.1725, lr_0 = 1.2554e-04\n",
      "Loss = 1.4997e-01, PNorm = 74.3724, GNorm = 0.8481, lr_0 = 1.2336e-04\n",
      "Validation auc = 0.771213\n",
      "Validation accuracy = 0.702703\n",
      " 90%|█████████ | 27/30 [34:22<03:45, 75.21s/it]Epoch 27\n",
      "Loss = 1.0045e-01, PNorm = 74.4077, GNorm = 0.7283, lr_0 = 1.2101e-04\n",
      "Loss = 9.7012e-02, PNorm = 74.4370, GNorm = 1.0604, lr_0 = 1.1891e-04\n",
      "Loss = 1.1012e-01, PNorm = 74.4655, GNorm = 1.1517, lr_0 = 1.1685e-04\n",
      "Loss = 1.3257e-01, PNorm = 74.4901, GNorm = 1.2359, lr_0 = 1.1482e-04\n",
      "Loss = 1.1002e-01, PNorm = 74.5133, GNorm = 1.1565, lr_0 = 1.1283e-04\n",
      "Validation auc = 0.775538\n",
      "Validation accuracy = 0.712838\n",
      " 93%|█████████▎| 28/30 [35:34<02:28, 74.38s/it]Epoch 28\n",
      "Loss = 1.1941e-01, PNorm = 74.5427, GNorm = 1.1346, lr_0 = 1.1068e-04\n",
      "Loss = 9.4914e-02, PNorm = 74.5684, GNorm = 0.9442, lr_0 = 1.0876e-04\n",
      "Loss = 9.6529e-02, PNorm = 74.5923, GNorm = 2.1303, lr_0 = 1.0687e-04\n",
      "Loss = 8.7619e-02, PNorm = 74.6114, GNorm = 0.9007, lr_0 = 1.0502e-04\n",
      "Loss = 1.1353e-01, PNorm = 74.6345, GNorm = 1.5856, lr_0 = 1.0320e-04\n",
      "Validation auc = 0.773788\n",
      "Validation accuracy = 0.712838\n",
      " 97%|█████████▋| 29/30 [36:47<01:13, 73.82s/it]Epoch 29\n",
      "Loss = 8.2754e-02, PNorm = 74.6598, GNorm = 0.7101, lr_0 = 1.0141e-04\n",
      "Loss = 1.1686e-01, PNorm = 74.6809, GNorm = 0.8081, lr_0 = 1.0000e-04\n",
      "Loss = 1.0037e-01, PNorm = 74.7014, GNorm = 0.9658, lr_0 = 1.0000e-04\n",
      "Loss = 9.3860e-02, PNorm = 74.7262, GNorm = 0.7594, lr_0 = 1.0000e-04\n",
      "Validation auc = 0.774391\n",
      "Validation accuracy = 0.704392\n",
      "100%|██████████| 30/30 [37:58<00:00, 75.94s/it]\n",
      "Model 4 best validation auc = 0.787978 on epoch 14\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Model 4 test auc = 0.731289                    \n",
      "Model 4 test accuracy = 0.664858\n",
      "Ensemble test auc = 0.743986\n",
      "Ensemble test accuracy = 0.679783\n",
      "1-fold cross validation\n",
      "\tSeed 0 ==> test auc = 0.743986\n",
      "\tSeed 0 ==> test accuracy = 0.679783\n",
      "Overall test auc = 0.743986 +/- 0.000000\n",
      "Overall test accuracy = 0.679783 +/- 0.000000\n",
      "Elapsed time = 3:14:08\n"
     ]
    }
   ],
   "source": [
    "train_filename = 'train.csv'\n",
    "val_filename = 'val.csv'\n",
    "arguments = [\n",
    "    '--data_path', os.path.join(endpoint_loc, train_filename),\n",
    "    '--dataset_type', 'classification',\n",
    "    '--config_path', os.path.join(model_loc, 'config.json'),\n",
    "    '--separate_test_path', os.path.join(endpoint_loc, val_filename), \n",
    "    '--save_dir', model_loc,\n",
    "    '--target_columns', 'Activity', \n",
    "    '--smiles_columns', 'SMILES',\n",
    "    '--features_generator', 'rdkit_2d_normalized', \n",
    "    '--no_features_scaling', \n",
    "    '--ensemble_size', '5', \n",
    "    '--extra_metrics', 'accuracy'\n",
    "]\n",
    "\n",
    "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
    "# chemprop.train.run_training(args=args)\n",
    "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training args\n",
      "Setting molecule featurization parameters to default.\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "739it [00:00, ?it/s]\n",
      "100%|██████████| 739/739 [00:32<00:00, 22.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating SMILES\n",
      "Test size = 737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:55<03:42, 55.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:39<02:26, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:25<01:34, 47.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:08<00:45, 45.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:49<00:00, 45.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to /dev/null\n",
      "Elapsed time = 0:04:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_filename = 'val.csv'\n",
    "arguments = [\n",
    "    '--test_path', os.path.join(endpoint_loc, val_filename), \n",
    "    '--preds_path', '/dev/null',\n",
    "    '--checkpoint_dir', model_loc,\n",
    "    '--smiles_columns', 'SMILES',\n",
    "    '--features_generator', 'rdkit_2d_normalized', \n",
    "    '--no_features_scaling'\n",
    "]\n",
    "\n",
    "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
    "preds = chemprop.train.make_predictions(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.014967243105638772],\n",
       " [0.9283272385597229],\n",
       " [0.7241867184638977],\n",
       " [0.1460847094655037],\n",
       " [0.9765593886375428],\n",
       " [0.9745757460594178],\n",
       " [0.6850063562393188],\n",
       " [0.6519476771354675],\n",
       " [0.9999996662139893],\n",
       " [0.7880078077316284],\n",
       " [0.9777578830718994],\n",
       " [0.008238770067691803],\n",
       " [0.20397643819451333],\n",
       " [0.3110180199146271],\n",
       " [0.1667617429047823],\n",
       " [0.2813951313495636],\n",
       " [0.00018670626614039065],\n",
       " [0.9776095390319824],\n",
       " [0.012821842404082417],\n",
       " [0.356750425696373],\n",
       " [0.9981843590736389],\n",
       " [0.0957473412156105],\n",
       " [0.0855846244841814],\n",
       " [0.08602171055972577],\n",
       " [0.45146154463291166],\n",
       " [0.9970054268836975],\n",
       " [0.5007620215415954],\n",
       " [0.3472181737422943],\n",
       " [0.7380805253982544],\n",
       " [0.2841791331768036],\n",
       " [0.17242426723241805],\n",
       " [0.6826781451702117],\n",
       " [0.4083179920911789],\n",
       " [0.6243569016456604],\n",
       " [0.020823880494572223],\n",
       " [0.9923450469970703],\n",
       " [0.4154783010482788],\n",
       " [0.9447962641716003],\n",
       " [0.8487432837486267],\n",
       " [0.40111584961414337],\n",
       " [0.9268442749977112],\n",
       " [0.9715529441833496],\n",
       " [0.9827993869781494],\n",
       " [0.7770680546760559],\n",
       " [0.9520861387252808],\n",
       " [0.9730715274810791],\n",
       " [0.3676705151796341],\n",
       " [0.3177596881985664],\n",
       " [0.12070590332150459],\n",
       " [0.2592086121439934],\n",
       " [0.14712967723608017],\n",
       " [0.041566509986296296],\n",
       " [0.35866931192576884],\n",
       " [0.45361104011535647],\n",
       " [0.9543522715568542],\n",
       " [0.01628791503608227],\n",
       " [0.453161358833313],\n",
       " [0.7185971736907959],\n",
       " [0.2871368542313576],\n",
       " [0.0031040316505823286],\n",
       " [0.3771373242139816],\n",
       " [0.5407722115516662],\n",
       " [0.30793818831443787],\n",
       " [0.1374698957428336],\n",
       " [0.8715829730033875],\n",
       " [0.5204443633556366],\n",
       " [0.5968418717384338],\n",
       " [0.1661746621131897],\n",
       " [0.8259571313858032],\n",
       " [0.008292380685452372],\n",
       " [0.29352623522281646],\n",
       " [0.9514675378799439],\n",
       " [0.8401821494102478],\n",
       " [0.8078551888465881],\n",
       " [0.8958041906356812],\n",
       " [0.9950116515159607],\n",
       " [0.02080967337824404],\n",
       " [0.9870103359222412],\n",
       " [0.0011651925335172564],\n",
       " [0.9949193716049194],\n",
       " [0.27085567861795423],\n",
       " [0.8675770282745361],\n",
       " [0.12142865061759948],\n",
       " [0.6371376156806946],\n",
       " [0.34028016328811644],\n",
       " [0.9603040814399719],\n",
       " [0.510234820842743],\n",
       " [0.9579470872879028],\n",
       " [0.1254049502313137],\n",
       " [0.1503304958343506],\n",
       " [0.9960754632949829],\n",
       " [0.8959993481636047],\n",
       " [0.857513689994812],\n",
       " [0.09627557769417763],\n",
       " [0.04023067280650139],\n",
       " [0.9099596977233887],\n",
       " [0.30833135545253754],\n",
       " [0.46514889001846316],\n",
       " [0.8953350186347961],\n",
       " [0.6666781187057496],\n",
       " [0.9706268191337586],\n",
       " [0.4376128315925598],\n",
       " [0.6507951498031617],\n",
       " [0.8232657313346863],\n",
       " [0.2617886759340763],\n",
       " [0.7998346805572509],\n",
       " [0.8801535844802857],\n",
       " [0.6261741936206817],\n",
       " [0.47452545911073685],\n",
       " [0.9346436262130737],\n",
       " [0.12210448533296585],\n",
       " [0.36589459478855135],\n",
       " [0.38648254573345187],\n",
       " [0.25049684941768646],\n",
       " [0.969277846813202],\n",
       " [0.029079301659658087],\n",
       " [0.04482379266992211],\n",
       " [0.1264422245323658],\n",
       " [0.016570151410996915],\n",
       " [0.6392368137836456],\n",
       " [0.07989581283181905],\n",
       " [0.9641590595245362],\n",
       " [0.7600613594055176],\n",
       " [0.30142322182655334],\n",
       " [0.6680949211120606],\n",
       " [0.5128679573535919],\n",
       " [0.6945621430873871],\n",
       " [0.70062096118927],\n",
       " [0.9651993989944458],\n",
       " [0.9261620998382568],\n",
       " [0.7772024273872375],\n",
       " [0.7225653767585755],\n",
       " [0.3168686509132385],\n",
       " [0.4622832715511322],\n",
       " [0.8388178467750549],\n",
       " [0.29116206616163254],\n",
       " [0.7922456383705139],\n",
       " [0.9951326847076416],\n",
       " [0.35694273710250857],\n",
       " [0.3838018223643303],\n",
       " [0.9841047167778015],\n",
       " [0.19147718846797943],\n",
       " [0.2912121802568436],\n",
       " [0.9737415790557862],\n",
       " [0.5332038998603821],\n",
       " [0.9571076154708862],\n",
       " [0.7629750847816468],\n",
       " [0.6213547348976135],\n",
       " [0.4571349799633026],\n",
       " [0.3166760548949242],\n",
       " [0.9139952898025513],\n",
       " [0.7563229680061341],\n",
       " [0.8989406943321228],\n",
       " [0.9408522009849548],\n",
       " [0.9210603356361389],\n",
       " [0.7378857612609864],\n",
       " [0.8427083849906921],\n",
       " [0.9874124169349671],\n",
       " [0.29698891639709474],\n",
       " [0.2048251748085022],\n",
       " [0.6035669803619385],\n",
       " [0.18727243095636367],\n",
       " [0.6557429790496826],\n",
       " [0.9974969983100891],\n",
       " [0.6330090165138245],\n",
       " [0.69162837266922],\n",
       " [0.053366255154833196],\n",
       " [0.9784693956375122],\n",
       " [0.015694965468719603],\n",
       " [0.7428817033767701],\n",
       " [0.011689990502782166],\n",
       " [0.5595550119876862],\n",
       " [0.7987424850463867],\n",
       " [0.21925683915615082],\n",
       " [0.7695257663726807],\n",
       " [0.8349482774734497],\n",
       " [0.16242597624659538],\n",
       " [0.30329072177410127],\n",
       " [0.8642951130867005],\n",
       " [0.06513950005173683],\n",
       " [0.8346921443939209],\n",
       " [0.617467713356018],\n",
       " [0.6083346366882324],\n",
       " [0.2611017346382141],\n",
       " [0.589467591047287],\n",
       " [0.874239444732666],\n",
       " [0.4661915361881256],\n",
       " [0.7393831133842468],\n",
       " [0.9332541227340698],\n",
       " [0.9999949216842652],\n",
       " [0.17171985805034637],\n",
       " [0.2787156492471695],\n",
       " [0.47134304642677305],\n",
       " [0.04344908063067123],\n",
       " [0.9538536667823792],\n",
       " [0.3626763939857483],\n",
       " [0.23339438885450364],\n",
       " [0.7668783783912658],\n",
       " [0.14871204793453216],\n",
       " [0.12641059532761573],\n",
       " [0.8634585261344909],\n",
       " [0.8291223526000977],\n",
       " [0.870821762084961],\n",
       " [0.5823741674423217],\n",
       " [0.33517298102378845],\n",
       " [0.27204216718673707],\n",
       " [0.5664484560489654],\n",
       " [0.9231141567230224],\n",
       " [0.8994065880775451],\n",
       " [0.6384170889854431],\n",
       " [0.048062131321057674],\n",
       " [0.10029353965073824],\n",
       " [0.15297292470932006],\n",
       " [0.863507080078125],\n",
       " [0.9551063418388367],\n",
       " [0.19940474331378938],\n",
       " [0.5297444999217987],\n",
       " [0.3150168299674988],\n",
       " [0.33187400102615355],\n",
       " [0.9999181628227234],\n",
       " [0.379783621430397],\n",
       " [0.7785921216011047],\n",
       " [0.8920786619186402],\n",
       " [0.9825034260749816],\n",
       " [0.9136149883270264],\n",
       " [0.34265884160995486],\n",
       " [0.9187731742858887],\n",
       " [0.35641008242964745],\n",
       " [0.9955622911453247],\n",
       " [0.8598522186279297],\n",
       " [0.699256443977356],\n",
       " [0.17225414514541626],\n",
       " [0.33257906436920165],\n",
       " [0.5617582082748414],\n",
       " [0.7405511736869812],\n",
       " [0.2001638352870941],\n",
       " [0.7063508868217468],\n",
       " [0.004660137480823323],\n",
       " [0.43762036263942716],\n",
       " [0.18924793750047683],\n",
       " [0.9251029372215271],\n",
       " [0.9734845519065857],\n",
       " [0.9252887725830078],\n",
       " [0.578820425271988],\n",
       " [0.8348725199699402],\n",
       " [0.8594078898429871],\n",
       " [0.9430771589279174],\n",
       " [0.8367496848106384],\n",
       " [0.1937226817011833],\n",
       " [0.9835880398750305],\n",
       " [0.5015738934278489],\n",
       " [0.6130536615848541],\n",
       " [0.12596582770347595],\n",
       " [0.9537918925285339],\n",
       " [0.41012532711029054],\n",
       " [0.9479905009269715],\n",
       " [0.1696239909157157],\n",
       " [0.047747202403843406],\n",
       " [0.9134263277053833],\n",
       " [0.9988118410110474],\n",
       " [0.011982683488167823],\n",
       " [0.4085428059101105],\n",
       " [0.11939131915569305],\n",
       " [0.07689186856150627],\n",
       " [0.5769748091697693],\n",
       " [0.8319306135177612],\n",
       " [0.963519561290741],\n",
       " [0.34964128136634826],\n",
       " [0.23709695637226105],\n",
       " [0.44060570001602173],\n",
       " [0.5785385012626648],\n",
       " [0.9377482533454895],\n",
       " [0.4710826873779297],\n",
       " [0.8522409319877624],\n",
       " [0.4354195147752762],\n",
       " [0.7074067234992981],\n",
       " [0.7258564352989196],\n",
       " [0.39122950434684756],\n",
       " [0.28097055554389955],\n",
       " [0.840589702129364],\n",
       " [7.656654861420975e-05],\n",
       " [0.616984748840332],\n",
       " [0.44268550872802737],\n",
       " [0.8181422233581543],\n",
       " [0.8931134581565857],\n",
       " [0.6753329873085022],\n",
       " [0.24645107090473176],\n",
       " [0.3340623378753662],\n",
       " [0.9914085984230041],\n",
       " [0.7078830361366272],\n",
       " [0.592529171705246],\n",
       " [0.00012492932782350862],\n",
       " [0.7893314778804779],\n",
       " [0.950956118106842],\n",
       " [0.752962839603424],\n",
       " [0.08338272029068321],\n",
       " [0.5922020196914672],\n",
       " [0.9944612860679627],\n",
       " [0.9942550301551819],\n",
       " [0.3278753340244293],\n",
       " [0.7409805595874787],\n",
       " [0.4078710347414017],\n",
       " [0.4010967820882797],\n",
       " [0.20550613850355148],\n",
       " [0.15055922260507942],\n",
       " [0.7285416841506958],\n",
       " [0.6515657901763916],\n",
       " [0.885229516029358],\n",
       " [0.9532331347465515],\n",
       " [0.715031361579895],\n",
       " ['Invalid SMILES'],\n",
       " [0.5061934053897857],\n",
       " [0.9999624729156494],\n",
       " [0.9520054340362549],\n",
       " [0.9579198598861695],\n",
       " [0.9848668813705445],\n",
       " [0.3010444972664118],\n",
       " [0.9877118468284607],\n",
       " [0.02134614735841751],\n",
       " [0.2025142252445221],\n",
       " [0.46856317222118377],\n",
       " [0.9144784569740295],\n",
       " [0.714634358882904],\n",
       " [0.9303885936737061],\n",
       " [0.6156443357467651],\n",
       " [0.921398651599884],\n",
       " [0.4231411337852478],\n",
       " [0.61418576836586],\n",
       " [0.8082103967666626],\n",
       " [0.48658376932144165],\n",
       " [0.6150114297866821],\n",
       " [0.8284243583679199],\n",
       " [0.9910168170928955],\n",
       " [0.8758224010467529],\n",
       " [0.8568788647651673],\n",
       " [0.0026792037941049786],\n",
       " [0.4418512791395187],\n",
       " [0.8446649670600891],\n",
       " [0.026701885089278222],\n",
       " [0.9975812792778015],\n",
       " [0.46747875213623047],\n",
       " [0.8432199478149414],\n",
       " [0.0493998683989048],\n",
       " [0.9665651917457581],\n",
       " [0.1906201273202896],\n",
       " [0.9128006100654602],\n",
       " [0.39110386073589326],\n",
       " [0.13443339616060257],\n",
       " [0.02922738641500473],\n",
       " [0.19170149862766267],\n",
       " [0.5505449593067169],\n",
       " [0.6992454767227173],\n",
       " [0.2225719928741455],\n",
       " [0.9866038680076599],\n",
       " [0.002831520097970497],\n",
       " [0.08120570741593838],\n",
       " [0.33545461893081663],\n",
       " [0.6235772490501403],\n",
       " [0.537339323759079],\n",
       " [0.994359302520752],\n",
       " [0.9911969184875489],\n",
       " [0.9653865456581116],\n",
       " [0.6076027452945709],\n",
       " [0.9914369463920594],\n",
       " [0.21969192624092101],\n",
       " [0.49720056653022765],\n",
       " [0.9858931541442871],\n",
       " [0.6627607941627502],\n",
       " [0.1467881327494979],\n",
       " [0.8424676537513733],\n",
       " [0.5518201351165771],\n",
       " [0.22391682863235474],\n",
       " [0.6494546115398407],\n",
       " [0.7802237510681153],\n",
       " [0.5657457947731018],\n",
       " [0.05405802768655121],\n",
       " [0.7156408369541168],\n",
       " [0.9755322098731994],\n",
       " [0.24990389943122865],\n",
       " [0.9571984529495239],\n",
       " [0.2916344553232193],\n",
       " [0.30838729739189147],\n",
       " [0.7171394467353821],\n",
       " [0.052136114216409624],\n",
       " [0.9933701276779174],\n",
       " [0.4879599928855896],\n",
       " [0.9879904389381409],\n",
       " [0.6430050909519196],\n",
       " [0.5658986866474152],\n",
       " [0.008097757934592664],\n",
       " [0.9123017191886902],\n",
       " [0.5190385341644287],\n",
       " [0.39163585305213927],\n",
       " [0.760615074634552],\n",
       " [0.6560077369213104],\n",
       " [0.4186443328857422],\n",
       " [0.014141609240323306],\n",
       " [0.883370554447174],\n",
       " [0.6395639061927796],\n",
       " [0.8588011741638184],\n",
       " [0.9650716781616211],\n",
       " [0.944746732711792],\n",
       " [0.914606511592865],\n",
       " [0.9990060091018677],\n",
       " [0.9457165718078613],\n",
       " [0.3808168351650238],\n",
       " [0.5981817722320557],\n",
       " [0.8278175234794617],\n",
       " [0.7231923818588257],\n",
       " [0.12300718389451504],\n",
       " [0.9564455986022949],\n",
       " [0.9912241458892822],\n",
       " [0.28448648266494275],\n",
       " [0.9899416208267212],\n",
       " [0.8183626770973206],\n",
       " [0.7600822567939758],\n",
       " [0.1511923313140869],\n",
       " [0.129223720356822],\n",
       " [0.032678714208304885],\n",
       " [0.9071877360343933],\n",
       " [0.48441221117973327],\n",
       " [0.024914359115064143],\n",
       " [0.7251238346099853],\n",
       " [0.03944498300552368],\n",
       " [0.9863169074058533],\n",
       " [0.6279892027378082],\n",
       " [0.9179007649421692],\n",
       " [0.656936825811863],\n",
       " [0.9701436758041382],\n",
       " [0.292686178535223],\n",
       " [0.2773144394159317],\n",
       " [0.6862093806266785],\n",
       " [0.209123231517151],\n",
       " [0.9943162798881531],\n",
       " [0.8406601428985596],\n",
       " [0.4955309689044952],\n",
       " [0.6094299793243408],\n",
       " [0.9338510990142822],\n",
       " [0.8812757968902588],\n",
       " [0.9910027027130127],\n",
       " [0.2424127370119095],\n",
       " [0.33953734040260314],\n",
       " [0.390155927836895],\n",
       " [0.2610042214393616],\n",
       " [0.25647646337747576],\n",
       " [0.69703009724617],\n",
       " [0.5021211117506027],\n",
       " [0.9889506220817565],\n",
       " [0.09508249328937382],\n",
       " [0.029691155720502137],\n",
       " [0.6607727527618408],\n",
       " [0.7018989622592926],\n",
       " [0.5318610012531281],\n",
       " [0.9620739936828613],\n",
       " [0.7093810796737671],\n",
       " [0.7200703263282776],\n",
       " [0.372653192281723],\n",
       " [0.3120707839727402],\n",
       " [0.9989901781082153],\n",
       " [0.9090136528015137],\n",
       " [0.9881024837493897],\n",
       " [0.09538832630496472],\n",
       " [0.9675356030464173],\n",
       " [0.533616092801094],\n",
       " [0.8123501420021058],\n",
       " [0.9768201112747192],\n",
       " [0.6712102293968201],\n",
       " [0.9571980595588684],\n",
       " [0.9557470560073853],\n",
       " [0.9276852011680603],\n",
       " [0.6949818968772888],\n",
       " [0.9007681608200073],\n",
       " [0.8059766054153442],\n",
       " [0.570056003332138],\n",
       " [0.9625782608985901],\n",
       " [0.15096765458583833],\n",
       " [0.8905683636665345],\n",
       " [0.13768564984202386],\n",
       " [0.19236838519573213],\n",
       " [0.27418518662452696],\n",
       " [0.8018282055854797],\n",
       " [0.005039179394952953],\n",
       " [0.8450377821922302],\n",
       " [0.09617334939539432],\n",
       " [0.9287332415580749],\n",
       " [0.12078796178102494],\n",
       " [0.5144928455352783],\n",
       " [0.09493240118026733],\n",
       " [0.9216108918190002],\n",
       " [0.8563943386077881],\n",
       " [0.5442214250564575],\n",
       " [0.9903923988342285],\n",
       " [0.7835201621055603],\n",
       " [0.43207372426986695],\n",
       " [0.7478806138038635],\n",
       " [0.9418587446212768],\n",
       " [0.8837647676467896],\n",
       " [0.22171723004430532],\n",
       " [0.6648681700229645],\n",
       " [0.8954877018928528],\n",
       " [0.9815822243690491],\n",
       " [0.8328544497489929],\n",
       " [0.8479119777679444],\n",
       " [0.27900864705443384],\n",
       " [0.7035624504089355],\n",
       " [0.05647174064069986],\n",
       " [0.9860356330871582],\n",
       " [0.755672299861908],\n",
       " [0.09498031586408615],\n",
       " [0.60112144947052],\n",
       " [0.6794101178646088],\n",
       " [0.46606749296188354],\n",
       " [0.9198327779769897],\n",
       " [0.809959614276886],\n",
       " [0.14382383953779937],\n",
       " [0.3695643901824951],\n",
       " [0.4906511098146439],\n",
       " [0.9418863773345947],\n",
       " [0.5914208471775055],\n",
       " [0.25724210143089293],\n",
       " [0.9884495496749878],\n",
       " [0.2110040694475174],\n",
       " [0.9957312822341919],\n",
       " [0.4871362864971161],\n",
       " [0.06651336178183556],\n",
       " [0.8227932691574097],\n",
       " [0.9745559096336365],\n",
       " [0.6844829678535461],\n",
       " [0.2637890249490738],\n",
       " [0.03353334413841367],\n",
       " [0.24834413155913354],\n",
       " [0.8397010922431946],\n",
       " [0.6874274373054504],\n",
       " [0.6657218694686889],\n",
       " [0.6394278407096863],\n",
       " [0.18289178162813186],\n",
       " [0.9583619594573974],\n",
       " [0.5022735357284546],\n",
       " [0.11529382765293121],\n",
       " [0.9753562569618225],\n",
       " [0.9108772993087768],\n",
       " [0.5939121901988983],\n",
       " [0.3352501530200243],\n",
       " [0.11134677082300186],\n",
       " [0.18844503164291382],\n",
       " [0.19220635592937468],\n",
       " [0.6336041927337647],\n",
       " [0.34333075284957887],\n",
       " [0.22624215483665466],\n",
       " [0.38428389430046084],\n",
       " [0.932759964466095],\n",
       " [0.8615773558616638],\n",
       " [0.3281639337539673],\n",
       " [0.2079426757991314],\n",
       " [0.7747222423553467],\n",
       " [0.6992180168628692],\n",
       " [0.011820404417812824],\n",
       " [0.8997039794921875],\n",
       " [0.0708661425858736],\n",
       " [0.33551199436187745],\n",
       " [0.6165565729141236],\n",
       " [0.012727364432066679],\n",
       " [0.9443717479705811],\n",
       " [0.7291342139244079],\n",
       " [0.6537215650081635],\n",
       " [0.9789289474487305],\n",
       " [0.9259177684783936],\n",
       " [0.7592203259468079],\n",
       " [0.3283978760242462],\n",
       " [0.3909816205501556],\n",
       " [0.5674687951803208],\n",
       " [0.9248412132263184],\n",
       " [0.6610556840896606],\n",
       " [0.2294627271592617],\n",
       " [0.8871614336967468],\n",
       " [0.9042007803916932],\n",
       " [0.6597419083118439],\n",
       " [0.9541192650794983],\n",
       " [0.07252802550792695],\n",
       " [0.26119292676448824],\n",
       " [0.4268099442124367],\n",
       " [0.954488730430603],\n",
       " [0.27613371461629865],\n",
       " [0.3867186546325684],\n",
       " [0.3243729531764984],\n",
       " [0.35996206253767016],\n",
       " [0.9383167028427124],\n",
       " [0.258251878619194],\n",
       " [0.006267373621813022],\n",
       " [0.10436526983976364],\n",
       " [0.1813075751066208],\n",
       " [0.7711613774299622],\n",
       " [0.6002682030200959],\n",
       " [0.9475967645645141],\n",
       " [0.8225185513496399],\n",
       " [0.2335247963666916],\n",
       " [0.7456744909286499],\n",
       " [0.004233165550976992],\n",
       " [0.3673027753829956],\n",
       " [0.995721435546875],\n",
       " [0.5520971477031708],\n",
       " [0.715422785282135],\n",
       " [0.09087903276085854],\n",
       " [0.03464203029870987],\n",
       " [0.44232853651046755],\n",
       " [0.8153279185295105],\n",
       " [0.7806737303733826],\n",
       " [0.547662752866745],\n",
       " [0.04602948129177094],\n",
       " [0.3286264330148697],\n",
       " [0.42366127073764803],\n",
       " [0.8477218627929688],\n",
       " [0.02151108328253031],\n",
       " [0.8582456827163696],\n",
       " [0.09222701322287322],\n",
       " [0.9816627860069275],\n",
       " [0.23705004379153252],\n",
       " [0.8549256205558777],\n",
       " [0.9752852082252502],\n",
       " [0.8652910470962525],\n",
       " [0.06124120503664017],\n",
       " [0.015590772544965149],\n",
       " [0.7513589084148407],\n",
       " [0.050044409558176996],\n",
       " [0.11757328808307647],\n",
       " [0.8674138069152832],\n",
       " [0.6469899892807007],\n",
       " [0.8176691055297851],\n",
       " [0.9500319361686707],\n",
       " [0.013922631926834583],\n",
       " [0.9831936001777649],\n",
       " [0.9908521175384521],\n",
       " [0.13161565959453583],\n",
       " [0.931851327419281],\n",
       " [0.9307880640029907],\n",
       " [0.24452387392520905],\n",
       " [0.7745521068572998],\n",
       " [0.9903431296348572],\n",
       " [0.6854867696762085],\n",
       " [0.2430582046508789],\n",
       " [0.2011398494243622],\n",
       " [0.48471052050590513],\n",
       " [0.31543655693531036],\n",
       " [0.8429672002792359],\n",
       " [0.9861117720603942],\n",
       " [0.3374180763959885],\n",
       " [0.9139688611030579],\n",
       " [0.33247531950473785],\n",
       " [0.5080872654914856],\n",
       " [0.2573630779981613],\n",
       " [0.6784316241741181],\n",
       " [0.6882577538490295],\n",
       " [0.9986101865768433],\n",
       " [0.61381796002388],\n",
       " [0.3807728737592697],\n",
       " [0.6879443407058716],\n",
       " [0.21846034079790116],\n",
       " [0.009226627508178353],\n",
       " [0.27532678097486496],\n",
       " [0.5498360395431519],\n",
       " [0.104938904941082],\n",
       " [0.4240090996026993],\n",
       " [0.13717708736658096],\n",
       " [0.6156605899333953],\n",
       " [0.9950165629386902],\n",
       " [0.998382568359375],\n",
       " [0.96703542470932],\n",
       " [0.4114623412489891],\n",
       " [0.21939000487327576],\n",
       " [0.8974560022354126],\n",
       " [0.32352508008480074],\n",
       " [0.934454345703125],\n",
       " [0.03584012677893043],\n",
       " [0.43689554631710054],\n",
       " [0.9886614680290222],\n",
       " [0.1543547298759222],\n",
       " [0.7251324951648712],\n",
       " [0.9679538130760192],\n",
       " [0.18551352024078369],\n",
       " [0.3195830449461937],\n",
       " ['Invalid SMILES'],\n",
       " [0.3814014047384262],\n",
       " [0.43715386390686034],\n",
       " [0.6207242012023926],\n",
       " [0.9697303652763367],\n",
       " [0.44593616724014284],\n",
       " [0.9711467862129212],\n",
       " [0.22966932505369186],\n",
       " [0.05978575497865677],\n",
       " [0.20130025446414948],\n",
       " [0.9818388223648071],\n",
       " [0.9861985683441162],\n",
       " [0.5384094655513764],\n",
       " [0.9816379189491272],\n",
       " [0.4014968365430832],\n",
       " [0.7030557990074158],\n",
       " [0.403764134645462],\n",
       " [0.47689774334430696],\n",
       " [0.8880277276039124],\n",
       " [0.7486836314201355],\n",
       " [0.8728965044021606],\n",
       " [0.1213860735297203],\n",
       " [0.022685486800037326],\n",
       " [0.8612718701362609],\n",
       " [0.6629071176052094],\n",
       " [0.2008109986782074],\n",
       " [0.20907709002494812],\n",
       " [0.11960307166446],\n",
       " [0.9905954718589782],\n",
       " [0.6860148668289184],\n",
       " [0.9350506067276001],\n",
       " [0.14471865594387054],\n",
       " [0.9987715959548951],\n",
       " [0.001629990470246412],\n",
       " [0.49863575100898744],\n",
       " [0.10372034460306168],\n",
       " [0.4398191154003143],\n",
       " [0.17022776305675508],\n",
       " [0.4795334700495005],\n",
       " [0.918274462223053],\n",
       " [0.8546719670295715],\n",
       " [0.9765257000923157],\n",
       " [0.989082932472229],\n",
       " [0.9487197041511536],\n",
       " [0.4623057872056961],\n",
       " [0.6896696448326111],\n",
       " [0.003542197891511023],\n",
       " [0.02452357579022646],\n",
       " [0.5681937754154205],\n",
       " [0.9932981729507446],\n",
       " [0.3058856278657913],\n",
       " [0.19784718304872512],\n",
       " [0.07852383963763714],\n",
       " [0.8065299749374389],\n",
       " [0.19839075952768326],\n",
       " [0.5738459825515747],\n",
       " [0.8060975790023803],\n",
       " [0.23407420814037322],\n",
       " [0.9417502164840699]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextAID",
   "language": "python",
   "name": "nextaid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
