{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, rdFingerprintGenerator\n",
    "from rdkit import DataStructs\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = 'skin-sensitization'\n",
    "endpoint = 'eye-irritation'\n",
    "\n",
    "loc = r'D:\\School\\Semester3\\Seminar - Reproducibility\\seminar-toxicity\\data'\n",
    "endpoint_loc = os.path.join(loc, endpoint)\n",
    "model = r'D:\\School\\Semester3\\Seminar - Reproducibility\\seminar-toxicity\\src\\models'\n",
    "model_loc = os.path.join(model, endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train.csv'\n",
    "df_train = pd.read_csv(os.path.join(endpoint_loc, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'val.csv'\n",
    "df_val = pd.read_csv(os.path.join(endpoint_loc, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles = df_train['SMILES'].to_numpy()\n",
    "train_labels = df_train['Activity'].to_numpy()\n",
    "val_smiles = df_val['SMILES'].to_numpy()\n",
    "val_labels = df_val['Activity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train size smiles :', train_smiles.shape)\n",
    "print('train size labels :', train_labels.shape)\n",
    "print('pos samples in train size :', train_labels[train_labels == 1].shape)\n",
    "print('neg samples in train size :', train_labels[train_labels == 0].shape)\n",
    "print('val size smiles :', val_smiles.shape)\n",
    "print('val size labels :', val_labels.shape)\n",
    "print('pos samples in val size :', val_labels[val_labels == 1].shape)\n",
    "print('neg samples in val size :', val_labels[val_labels == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAACS(smiles_array, labels):\n",
    "    fps = []\n",
    "    y = []\n",
    "    for smiles, label in zip(smiles_array, labels):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            pass\n",
    "        else:\n",
    "            fps.append(np.array(MACCSkeys.GenMACCSKeys(mol)))\n",
    "            y.append(label)\n",
    "\n",
    "    assert len(fps) == len(y)\n",
    "    \n",
    "    return np.array(fps), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fingerprints, train_labels = get_MAACS(train_smiles, train_labels)\n",
    "val_fingerprints, val_labels = get_MAACS(val_smiles, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train size fingerprints :', train_fingerprints.shape)\n",
    "print('train size labels :', train_labels.shape)\n",
    "print('pos samples in train size :', train_labels[train_labels == 1].shape)\n",
    "print('neg samples in train size :', train_labels[train_labels == 0].shape)\n",
    "print('val size fingerprints :', val_fingerprints.shape)\n",
    "print('val size labels :', val_labels.shape)\n",
    "print('pos samples in val size :', val_labels[val_labels == 1].shape)\n",
    "print('neg samples in val size :', val_labels[val_labels == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, xtrain, ytrain):\n",
    "    n = trial.suggest_int('n_estimators', 2, 200)\n",
    "    rf = RandomForestClassifier(n_estimators = n)\n",
    "\n",
    "    scores = cross_validate(rf, xtrain, ytrain, cv=5, scoring='roc_auc')\n",
    "    mean_roc = scores['test_score'].mean()\n",
    "\n",
    "    return 1/(mean_roc + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(study_name='rf_study', storage='sqlite:///rf_study.db')  # Create a new study.\n",
    "study.optimize(lambda trial: objective(trial, train_fingerprints, train_labels), n_trials=20)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 159, random_state=1234)\n",
    "rf.fit(train_fingerprints, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions on the test dataset \n",
    "y_pred = rf.predict(train_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train accuracy = ', (y_pred == train_labels).sum()/len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(val_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Val accuracy = ', (y_pred == val_labels).sum()/len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextAID",
   "language": "python",
   "name": "nextaid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
